---
title: "ìœˆë„ì‰(Windowing) ê¸°ë²•: ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ì™€ ë°ì´í„° ë¶„ì„ì˜ í•µì‹¬"
categories: 
  - Data Engineering
  - Stream Processing
  - Software Architecture
tags:
  - Windowing
  - Stream Processing
  - Real-time Analytics
  - Data Engineering
  - Apache Kafka
  - Apache Flink
  - Time-based Windows
  - Sliding Windows
  - Session Windows
  - Data Streaming
  - Real-time Processing
  - Big Data
  - Analytics
  - Performance Optimization
  - EventTime
  - Watermark
  - Out-of-Order
  - Late Data
  - Tumbling Window
  - Sliding Window
  - Session Window
  - Aggregation
  - Stateful Processing
  - Stateless Processing
  - Window Trigger
  - Window Function
  - Window Join
  - Windowed Aggregation
  - Stream Analytics
  - Real-time Dashboard
  - Data Lake
  - Lambda Architecture
  - Kappa Architecture
  - Micro-batch
  - Throughput
  - Latency
  - Backpressure
  - Checkpointing
  - Fault Tolerance
  - Exactly-Once
date: 2025-07-29
image: index.png
description: "ìœˆë„ì‰(Windowing)ì€ ìŠ¤íŠ¸ë¦¼ ë°ì´í„° ì²˜ë¦¬ì—ì„œ ì‹œê°„, ê°œìˆ˜, ì„¸ì…˜ ë“± ë‹¤ì–‘í•œ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê·¸ë£¹í™”í•˜ì—¬ ì‹¤ì‹œê°„ ë¶„ì„ê³¼ ì§‘ê³„ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í•µì‹¬ ê¸°ìˆ ì´ë‹¤. Apache Kafka, Flink ë“± ì£¼ìš” ìŠ¤íŠ¸ë¦¼ í”„ë¡œì„¸ì‹± ì—”ì§„ì—ì„œ í•„ìˆ˜ì ìœ¼ë¡œ í™œìš©ë˜ë©°, ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ê³¼ íŒ¨í„´ ì¸ì‹, ì‹œìŠ¤í…œ ë¶€í•˜ ìµœì í™”ì— ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤. ë³¸ ê°€ì´ë“œì—ì„œëŠ” íƒ€ì„ ìœˆë„ìš°, ìŠ¬ë¼ì´ë”© ìœˆë„ìš°, ì„¸ì…˜ ìœˆë„ìš° ë“± ì£¼ìš” ìœˆë„ì‰ ìœ í˜•ê³¼ ì‹¤ì œ ì ìš© ì‚¬ë¡€, ì„±ëŠ¥ ìµœì í™” ì „ëµê¹Œì§€ ì²´ê³„ì ìœ¼ë¡œ ì„¤ëª…í•œë‹¤."
---

ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ì—ì„œ ìœˆë„ì‰(Windowing) ê¸°ë²•ì€ ë°ì´í„° ë¶„ì„ê³¼ ì§‘ê³„ì˜ í•µì‹¬ì´ ë˜ëŠ” ê¸°ìˆ ì´ë‹¤. ë³¸ ê°€ì´ë“œì—ì„œëŠ” ìœˆë„ì‰ì˜ ê¸°ë³¸ ê°œë…ë¶€í„° ë‹¤ì–‘í•œ ìœˆë„ìš° ìœ í˜•, ì‹¤ì œ ì ìš© ì‚¬ë¡€, ê·¸ë¦¬ê³  ì„±ëŠ¥ ìµœì í™” ì „ëµê¹Œì§€ ì²´ê³„ì ìœ¼ë¡œ ì„¤ëª…í•  ê²ƒì´ë‹¤. ì´ ê¸€ì„ í†µí•´ ìŠ¤íŠ¸ë¦¼ ë°ì´í„° í™˜ê²½ì—ì„œ ìœˆë„ì‰ ê¸°ë²•ì´ ì™œ ì¤‘ìš”í•œì§€, ê·¸ë¦¬ê³  ì–´ë–»ê²Œ í™œìš©í•  ìˆ˜ ìˆëŠ”ì§€ ëª…í™•í•˜ê²Œ ì´í•´í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.


## ìœˆë„ì‰ ê¸°ë²•ì´ë€?

ìœˆë„ì‰(Windowing) ê¸°ë²•ì€ **ì—°ì†ì ì¸ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì—ì„œ íŠ¹ì • ì‹œê°„ ë²”ìœ„ë‚˜ ê°œìˆ˜ ë²”ìœ„ ë‚´ì˜ ë°ì´í„°ë¥¼ ê·¸ë£¹í™”í•˜ì—¬ ì²˜ë¦¬í•˜ëŠ” ê¸°ìˆ **ì´ë‹¤. ë§ˆì¹˜ ì°½ë¬¸(window)ì„ í†µí•´ ë°ì´í„°ë¥¼ ë°”ë¼ë³´ëŠ” ê²ƒê³¼ ê°™ì•„ì„œ, ì´ ì°½ë¬¸ì€ ì‹œê°„ì´ë‚˜ ê°œìˆ˜ì— ë”°ë¼ ì´ë™í•˜ë©° ì°½ë¬¸ ì•ˆì— ë“¤ì–´ì˜¨ ë°ì´í„°ë“¤ë§Œì„ ëŒ€ìƒìœ¼ë¡œ ë¶„ì„ê³¼ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•œë‹¤.

### ê¸°ë³¸ ê°œë…

ìœˆë„ì‰ì˜ í•µì‹¬ ì•„ì´ë””ì–´ëŠ” **ì—°ì†ì ì¸ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì—ì„œ íŠ¹ì • ë²”ìœ„ì˜ ë°ì´í„°ë§Œì„ ì„ íƒì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ê²ƒ**ì´ë‹¤. ì´ëŠ” ë§ˆì¹˜ ì‹œê°„ì˜ íë¦„ì— ë”°ë¼ ì›€ì§ì´ëŠ” ì°½ë¬¸(window)ì„ í†µí•´ ë°ì´í„°ë¥¼ ë°”ë¼ë³´ëŠ” ê²ƒê³¼ ê°™ë‹¤.

#### ìœˆë„ì‰ì˜ í•µì‹¬ ìš”ì†Œ

1. **ìœˆë„ìš° í¬ê¸° (Window Size)**: í•œ ë²ˆì— ì²˜ë¦¬í•  ë°ì´í„°ì˜ ë²”ìœ„
2. **ìœˆë„ìš° ìŠ¬ë¼ì´ë“œ (Window Slide)**: ìœˆë„ìš°ê°€ ì´ë™í•˜ëŠ” ê°„ê²©
3. **ìœˆë„ìš° í•¨ìˆ˜ (Window Function)**: ìœˆë„ìš° ë‚´ ë°ì´í„°ì— ì ìš©í•  ì—°ì‚°

```python
# ìœˆë„ì‰ì˜ ê¸°ë³¸ ê°œë…ì„ ë³´ì—¬ì£¼ëŠ” ì˜ˆì‹œ
from collections import deque
import time

class BasicWindow:
    def __init__(self, window_size):
        self.window_size = window_size
        self.data_window = deque(maxlen=window_size)
    
    def add_data(self, data_point):
        """ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìœˆë„ìš°ì— ì¶”ê°€"""
        self.data_window.append(data_point)
        return self.process_window()
    
    def process_window(self):
        """ìœˆë„ìš° ë‚´ ë°ì´í„° ì²˜ë¦¬"""
        if not self.data_window:
            return None
        
        return {
            'count': len(self.data_window),
            'average': sum(self.data_window) / len(self.data_window),
            'max': max(self.data_window),
            'min': min(self.data_window)
        }

# ì‚¬ìš© ì˜ˆì‹œ
window = BasicWindow(window_size=5)
data_stream = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]

for data in data_stream:
    result = window.add_data(data)
    if result:
        print(f"ìœˆë„ìš° ì²˜ë¦¬ ê²°ê³¼: {result}")
```

#### ìœˆë„ì‰ì˜ ë™ì‘ ì›ë¦¬

```
ì‹œê°„ ì¶•: [1] [2] [3] [4] [5] [6] [7] [8] [9] [10]
                    â†‘
                í˜„ì¬ ì‹œì 

ìœˆë„ìš° í¬ê¸° 3ì¸ ê²½ìš°:
- ì‹œì  3: [1, 2, 3] ì²˜ë¦¬
- ì‹œì  4: [2, 3, 4] ì²˜ë¦¬  
- ì‹œì  5: [3, 4, 5] ì²˜ë¦¬
- ...

ìœˆë„ìš° í¬ê¸° 5ì¸ ê²½ìš°:
- ì‹œì  5: [1, 2, 3, 4, 5] ì²˜ë¦¬
- ì‹œì  6: [2, 3, 4, 5, 6] ì²˜ë¦¬
- ì‹œì  7: [3, 4, 5, 6, 7] ì²˜ë¦¬
- ...
```

#### ìœˆë„ì‰ì˜ ì¥ì 

1. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ì „ì²´ ìŠ¤íŠ¸ë¦¼ì„ ì €ì¥í•˜ì§€ ì•Šê³  í•„ìš”í•œ ë¶€ë¶„ë§Œ ìœ ì§€
2. **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ìµœì‹  ë°ì´í„°ì— ì§‘ì¤‘í•˜ì—¬ ë¹ ë¥¸ ì‘ë‹µ
3. **í™•ì¥ì„±**: ë°ì´í„° ì–‘ì´ ì¦ê°€í•´ë„ ì¼ì •í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
4. **ìœ ì—°ì„±**: ë‹¤ì–‘í•œ ìœˆë„ìš° í¬ê¸°ì™€ í•¨ìˆ˜ë¡œ ë‹¤ì–‘í•œ ë¶„ì„ ê°€ëŠ¥

### ìœˆë„ì‰ì˜ í•µì‹¬ íŠ¹ì§•

#### ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± (Memory Efficiency)

ìœˆë„ì‰ì˜ ê°€ì¥ í° ì¥ì ì€ **ë¬´í•œí•œ ìŠ¤íŠ¸ë¦¼ ë°ì´í„°ë¥¼ ëª¨ë‘ ì €ì¥í•  í•„ìš” ì—†ì´ í•„ìš”í•œ ë¶€ë¶„ë§Œ ì²˜ë¦¬**í•˜ëŠ” ê²ƒì´ë‹¤.

```python
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì˜ˆì‹œ
class MemoryEfficientWindow:
    def __init__(self, window_size):
        self.window_size = window_size
        self.data = deque(maxlen=window_size)  # ìµœëŒ€ í¬ê¸° ì œí•œ
    
    def add_data(self, value):
        self.data.append(value)
        # ìœˆë„ìš°ê°€ ê°€ë“ ì°¨ë©´ ìë™ìœ¼ë¡œ ê°€ì¥ ì˜¤ë˜ëœ ë°ì´í„° ì œê±°
        return self.calculate_stats()
    
    def calculate_stats(self):
        return {
            'count': len(self.data),
            'sum': sum(self.data),
            'avg': sum(self.data) / len(self.data) if self.data else 0
        }

# ë¬´í•œ ìŠ¤íŠ¸ë¦¼ì—ì„œë„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì¼ì •í•¨
window = MemoryEfficientWindow(1000)
for i in range(1000000):  # 100ë§Œ ê°œ ë°ì´í„°
    result = window.add_data(i)
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì€ í•­ìƒ 1000ê°œ ë°ì´í„°ë§Œí¼ë§Œ ìœ ì§€ë¨
```

#### ì‹¤ì‹œê°„ ì²˜ë¦¬ (Real-time Processing)

ìœˆë„ì‰ì€ **ìµœì‹  ë°ì´í„°ì— ì§‘ì¤‘í•˜ì—¬ ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ì„ ë³´ì¥**í•œë‹¤.

```python
class RealTimeWindow:
    def __init__(self, window_duration_seconds):
        self.window_duration = window_duration_seconds
        self.events = deque()
    
    def add_event(self, event):
        current_time = time.time()
        
        # ì˜¤ë˜ëœ ì´ë²¤íŠ¸ ì œê±°
        while self.events and self.events[0].timestamp < current_time - self.window_duration:
            self.events.popleft()
        
        self.events.append(event)
        
        # ì¦‰ì‹œ ì²˜ë¦¬ ê²°ê³¼ ë°˜í™˜
        return self.process_recent_events()
    
    def process_recent_events(self):
        # ìµœì‹  ì´ë²¤íŠ¸ë“¤ë§Œ ì²˜ë¦¬í•˜ì—¬ ë¹ ë¥¸ ì‘ë‹µ
        recent_events = list(self.events)[-10:]  # ìµœê·¼ 10ê°œë§Œ
        return {
            'recent_count': len(recent_events),
            'total_in_window': len(self.events)
        }
```

#### íŒ¨í„´ ì¸ì‹ (Pattern Recognition)

ìœˆë„ì‰(windowing)ì€ **ì§€ì •ëœ ì‹œê°„ ë˜ëŠ” ê°œìˆ˜ ë²”ìœ„ ë‚´ì˜ ë°ì´í„°ë§Œì„ ì§‘ì¤‘ì ìœ¼ë¡œ ë¶„ì„**í•˜ê¸° ë•Œë¬¸ì—, ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì—ì„œ ë°œìƒí•˜ëŠ” ë³€í™”ë‚˜ íŠ¸ë Œë“œë¥¼ ë¹ ë¥´ê²Œ í¬ì°©í•  ìˆ˜ ìˆë‹¤.  
ì´ ë°©ì‹ì€ ì „ì²´ ë°ì´í„°ê°€ ì•„ë‹Œ ìµœê·¼ ë°ì´í„° ì§‘í•©ë§Œì„ ëŒ€ìƒìœ¼ë¡œ í•˜ë¯€ë¡œ, **ë…¸ì´ì¦ˆì— ëœ ë¯¼ê°í•˜ê³ , ì‹œê³„ì—´ ë°ì´í„°ì˜ ìƒìŠ¹Â·í•˜ë½Â·ë³€ë™ íŒ¨í„´ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì§€**í•  ìˆ˜ ìˆë‹¤.  
ë˜í•œ, ìœˆë„ìš° ë‚´ ë°ì´í„°ì˜ í‰ê· , ë¶„ì‚°, ì´ë™í‰ê·  ë“± ë‹¤ì–‘í•œ í†µê³„ì  íŠ¹ì§•ì„ ê³„ì‚°í•¨ìœ¼ë¡œì¨, **ì´ìƒì¹˜(anomaly)ë‚˜ ê¸‰ê²©í•œ ë³€í™”(trend shift)ë„ íš¨ê³¼ì ìœ¼ë¡œ íƒì§€**í•  ìˆ˜ ìˆë‹¤.

```python
class PatternRecognitionWindow:
    def __init__(self, window_size):
        self.window_size = window_size
        self.data = deque(maxlen=window_size)
    
    def detect_trend(self, new_value):
        self.data.append(new_value)
        
        if len(self.data) < 3:
            return "insufficient_data"
        
        # ìµœê·¼ 3ê°œ ê°’ìœ¼ë¡œ íŠ¸ë Œë“œ ë¶„ì„
        recent = list(self.data)[-3:]
        
        if recent[0] < recent[1] < recent[2]:
            return "increasing"
        elif recent[0] > recent[1] > recent[2]:
            return "decreasing"
        else:
            return "fluctuating"
    
    def detect_anomaly(self, new_value, threshold=2.0):
        self.data.append(new_value)
        
        if len(self.data) < 10:
            return False
        
        # Z-score ê¸°ë°˜ ì´ìƒê°’ íƒì§€
        values = list(self.data)
        mean = sum(values) / len(values)
        std_dev = (sum((x - mean) ** 2 for x in values) / len(values)) ** 0.5
        
        if std_dev == 0:
            return False
        
        z_score = abs((new_value - mean) / std_dev)
        return z_score > threshold
```

#### ë¦¬ì†ŒìŠ¤ ìµœì í™” (Resource Optimization)

ìœˆë„ì‰ì€ **ì²˜ë¦¬í•´ì•¼ í•  ë°ì´í„° ì–‘ì„ ì œí•œí•˜ì—¬ ì‹œìŠ¤í…œ ë¶€í•˜ë¥¼ ê°ì†Œ**ì‹œí‚¨ë‹¤.

```python
class ResourceOptimizedWindow:
    def __init__(self, max_events_per_second=1000):
        self.max_events = max_events_per_second
        self.events = deque()
        self.last_processing_time = time.time()
    
    def add_event(self, event):
        current_time = time.time()
        self.events.append(event)
        
        # ì²˜ë¦¬ ë¹ˆë„ ì œí•œìœ¼ë¡œ CPU ë¶€í•˜ ê°ì†Œ
        if current_time - self.last_processing_time >= 1.0:  # 1ì´ˆë§ˆë‹¤ ì²˜ë¦¬
            result = self.process_batch()
            self.last_processing_time = current_time
            return result
        
        return None
    
    def process_batch(self):
        # ë°°ì¹˜ ì²˜ë¦¬ë¡œ íš¨ìœ¨ì„± í–¥ìƒ
        batch = list(self.events)
        self.events.clear()
        
        return {
            'processed_count': len(batch),
            'avg_value': sum(e.value for e in batch) / len(batch) if batch else 0
        }
```

#### í™•ì¥ì„± (Scalability)

ìœˆë„ì‰ì€ **ë°ì´í„° ì–‘ì´ ì¦ê°€í•´ë„ ì¼ì •í•œ ì„±ëŠ¥ì„ ìœ ì§€**í•œë‹¤.

```python
class ScalableWindow:
    def __init__(self, window_size):
        self.window_size = window_size
        self.sum = 0
        self.count = 0
        self.data = deque(maxlen=window_size)
    
    def add_value(self, value):
        # O(1) ì‹œê°„ ë³µì¡ë„ë¡œ í™•ì¥ ê°€ëŠ¥í•œ ì²˜ë¦¬
        if len(self.data) == self.window_size:
            old_value = self.data.popleft()
            self.sum -= old_value
            self.count -= 1
        
        self.data.append(value)
        self.sum += value
        self.count += 1
        
        return {
            'average': self.sum / self.count,
            'count': self.count
        }
```

## ìœˆë„ì‰ì˜ í•„ìš”ì„±ê³¼ ì¤‘ìš”ì„±

### ì™œ ìœˆë„ì‰ì´ í•„ìš”í•œê°€?

í˜„ëŒ€ì˜ ë°ì´í„° í™˜ê²½ì—ì„œëŠ” ì´ˆë‹¹ ìˆ˜ë§Œ ê±´ì˜ ì´ë²¤íŠ¸ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤. ì´ëŸ¬í•œ ëŒ€ìš©ëŸ‰ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ì„œëŠ” ìœˆë„ì‰ ê¸°ë²•ì´ í•„ìˆ˜ì ì´ë‹¤.

#### ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì™€ ìœˆë„ì‰ì˜ í•„ìš”ì„±

**1. ê¸ˆìœµ ê±°ë˜ ì‹œìŠ¤í…œ**
```python
# ì´ˆë‹¹ ìˆ˜ì²œ ê±´ì˜ ì£¼ì‹ ê±°ë˜ ë°ì´í„°
class StockTradeAnalyzer:
    def __init__(self):
        self.price_window = deque(maxlen=100)  # ìµœê·¼ 100ê°œ ê±°ë˜
        self.volume_window = deque(maxlen=1000)  # ìµœê·¼ 1000ê°œ ê±°ë˜
    
    def process_trade(self, trade):
        self.price_window.append(trade.price)
        self.volume_window.append(trade.volume)
        
        # ì‹¤ì‹œê°„ ê°€ê²© ë³€ë™ ë¶„ì„
        price_volatility = self.calculate_volatility(list(self.price_window))
        
        # ê±°ë˜ëŸ‰ ê¸‰ì¦ íƒì§€
        volume_surge = self.detect_volume_surge(list(self.volume_window))
        
        return {
            'current_price': trade.price,
            'price_volatility': price_volatility,
            'volume_surge': volume_surge
        }
```

**2. ì›¹ ë¡œê·¸ ë¶„ì„**
```python
# ì´ˆë‹¹ ìˆ˜ë§Œ ê±´ì˜ ì›¹ì‚¬ì´íŠ¸ ì ‘ì† ë¡œê·¸
class WebLogAnalyzer:
    def __init__(self, window_minutes=5):
        self.window_minutes = window_minutes
        self.requests = deque()
        self.error_threshold = 0.1  # 10% ì—ëŸ¬ìœ¨ ì„ê³„ê°’
    
    def add_request(self, request):
        current_time = request.timestamp
        
        # 5ë¶„ ìœˆë„ìš° ë°–ì˜ ìš”ì²­ ì œê±°
        while self.requests and self.requests[0].timestamp < current_time - self.window_minutes * 60:
            self.requests.popleft()
        
        self.requests.append(request)
        
        # ì‹¤ì‹œê°„ ì„±ëŠ¥ ë¶„ì„
        return self.analyze_performance()
    
    def analyze_performance(self):
        if not self.requests:
            return {}
        
        total_requests = len(self.requests)
        error_requests = sum(1 for req in self.requests if req.status_code >= 400)
        error_rate = error_requests / total_requests
        
        return {
            'request_rate': total_requests / (self.window_minutes * 60),  # ìš”ì²­/ì´ˆ
            'error_rate': error_rate,
            'is_alert': error_rate > self.error_threshold
        }
```

**3. IoT ì„¼ì„œ ëª¨ë‹ˆí„°ë§**
```python
# ì´ˆë‹¹ ìˆ˜ë°± ê±´ì˜ ì„¼ì„œ ë°ì´í„°
class SensorMonitor:
    def __init__(self, sensor_id, window_size=60):
        self.sensor_id = sensor_id
        self.window_size = window_size
        self.readings = deque(maxlen=window_size)
        self.alert_threshold = 2.0  # Z-score ì„ê³„ê°’
    
    def add_reading(self, value, timestamp):
        self.readings.append({'value': value, 'timestamp': timestamp})
        
        if len(self.readings) >= 10:  # ìµœì†Œ ë°ì´í„° í•„ìš”
            anomaly = self.detect_anomaly(value)
            trend = self.analyze_trend()
            
            return {
                'sensor_id': self.sensor_id,
                'current_value': value,
                'is_anomaly': anomaly,
                'trend': trend,
                'avg_value': sum(r['value'] for r in self.readings) / len(self.readings)
            }
        return None
    
    def detect_anomaly(self, current_value):
        values = [r['value'] for r in self.readings]
        mean = sum(values) / len(values)
        std_dev = (sum((x - mean) ** 2 for x in values) / len(values)) ** 0.5
        
        if std_dev == 0:
            return False
        
        z_score = abs((current_value - mean) / std_dev)
        return z_score > self.alert_threshold
```

**4. ì†Œì…œ ë¯¸ë””ì–´ íŠ¸ë Œë“œ ë¶„ì„**
```python
# ì´ˆë‹¹ ìˆ˜ë§Œ ê±´ì˜ í¬ìŠ¤íŠ¸ì™€ ëŒ“ê¸€
class SocialMediaAnalyzer:
    def __init__(self, hashtag, window_hours=1):
        self.hashtag = hashtag
        self.window_hours = window_hours
        self.posts = deque()
        self.engagement_metrics = {}
    
    def add_post(self, post):
        current_time = post.timestamp
        
        # 1ì‹œê°„ ìœˆë„ìš° ë°–ì˜ í¬ìŠ¤íŠ¸ ì œê±°
        while self.posts and self.posts[0].timestamp < current_time - self.window_hours * 3600:
            old_post = self.posts.popleft()
            self.update_engagement_metrics(old_post, remove=True)
        
        self.posts.append(post)
        self.update_engagement_metrics(post, remove=False)
        
        return self.analyze_trends()
    
    def update_engagement_metrics(self, post, remove=False):
        factor = -1 if remove else 1
        
        self.engagement_metrics['total_likes'] = self.engagement_metrics.get('total_likes', 0) + factor * post.likes
        self.engagement_metrics['total_shares'] = self.engagement_metrics.get('total_shares', 0) + factor * post.shares
        self.engagement_metrics['total_comments'] = self.engagement_metrics.get('total_comments', 0) + factor * post.comments
    
    def analyze_trends(self):
        return {
            'hashtag': self.hashtag,
            'post_count': len(self.posts),
            'engagement_rate': (self.engagement_metrics.get('total_likes', 0) + 
                              self.engagement_metrics.get('total_shares', 0) + 
                              self.engagement_metrics.get('total_comments', 0)) / max(len(self.posts), 1),
            'trending_score': self.calculate_trending_score()
        }
```

#### ìœˆë„ì‰ì´ ì—†ì„ ë•Œì˜ ë¬¸ì œì 

1. **ë©”ëª¨ë¦¬ ë¶€ì¡±**: ë¬´í•œí•œ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì„ ëª¨ë‘ ì €ì¥í•˜ë ¤ë©´ ë¬´í•œí•œ ë©”ëª¨ë¦¬ê°€ í•„ìš”
2. **ì²˜ë¦¬ ì§€ì—°**: ì „ì²´ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•´ì•¼ í•˜ë¯€ë¡œ ì‹¤ì‹œê°„ ì‘ë‹µ ë¶ˆê°€ëŠ¥
3. **ë¦¬ì†ŒìŠ¤ ë‚­ë¹„**: ì˜¤ë˜ëœ ë°ì´í„°ë„ ê³„ì† ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ë¹„íš¨ìœ¨ì„±
4. **í™•ì¥ì„± í•œê³„**: ë°ì´í„° ì–‘ì´ ì¦ê°€í•˜ë©´ ì‹œìŠ¤í…œì´ í¬í™”ë¨

### ìœˆë„ì‰ì˜ ì¥ì 

1. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ**: ìœˆë„ìš° í¬ê¸°ì— ë”°ë¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì¼ì •í•˜ê²Œ ìœ ì§€ë¨
2. **ì‹¤ì‹œê°„ ë¶„ì„**: ìµœì‹  ë°ì´í„°ì— ëŒ€í•œ ì¦‰ê°ì ì¸ ì¸ì‚¬ì´íŠ¸ ì œê³µ
3. **í™•ì¥ì„±**: ë°ì´í„° ì–‘ì´ ì¦ê°€í•´ë„ ì¼ì •í•œ ì„±ëŠ¥ ìœ ì§€
4. **ìœ ì—°ì„±**: ë‹¤ì–‘í•œ ìœˆë„ìš° ìœ í˜•ìœ¼ë¡œ ë‹¤ì–‘í•œ ë¶„ì„ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±


## ìœˆë„ì‰ ê¸°ë²•ì˜ ì£¼ìš” ìœ í˜•

### ì‹œê°„ ê¸°ë°˜ ìœˆë„ìš° (Time-based Windows)

ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ ìœˆë„ìš°ë¥¼ ì •ì˜í•˜ëŠ” ê°€ì¥ ì¼ë°˜ì ì¸ ë°©ì‹ì´ë‹¤.

#### ê³ ì • ì‹œê°„ ìœˆë„ìš° (Fixed Time Windows)

```python
import time
from datetime import datetime, timedelta

class FixedTimeWindow:
    def __init__(self, window_duration_seconds):
        self.window_duration = window_duration_seconds
        self.current_window_start = None
        self.window_data = []
    
    def process_event(self, event):
        event_time = event.timestamp
        
        # ìƒˆë¡œìš´ ìœˆë„ìš° ì‹œì‘ í™•ì¸
        if (self.current_window_start is None or 
            event_time >= self.current_window_start + self.window_duration):
            
            # ì´ì „ ìœˆë„ìš° ì²˜ë¦¬
            if self.window_data:
                result = self.process_window(self.window_data)
                print(f"ìœˆë„ìš° ì²˜ë¦¬ ì™„ë£Œ: {result}")
            
            # ìƒˆ ìœˆë„ìš° ì‹œì‘
            self.current_window_start = event_time
            self.window_data = [event]
        else:
            self.window_data.append(event)
    
    def process_window(self, data):
        return {
            'window_start': self.current_window_start,
            'event_count': len(data),
            'avg_value': sum(e.value for e in data) / len(data) if data else 0
        }
```

#### ìŠ¬ë¼ì´ë”© ì‹œê°„ ìœˆë„ìš° (Sliding Time Windows)

```python
class SlidingTimeWindow:
    def __init__(self, window_duration, slide_interval):
        self.window_duration = window_duration
        self.slide_interval = slide_interval
        self.events = deque()
    
    def add_event(self, event):
        current_time = event.timestamp
        
        # ìœˆë„ìš° ë°–ì˜ ì´ë²¤íŠ¸ ì œê±°
        while self.events and self.events[0].timestamp < current_time - self.window_duration:
            self.events.popleft()
        
        self.events.append(event)
        
        # ìŠ¬ë¼ì´ë“œ ê°„ê²©ì— ë”°ë¥¸ ì²˜ë¦¬
        if len(self.events) > 0:
            return self.process_window(list(self.events))
    
    def process_window(self, events):
        return {
            'window_size': len(events),
            'time_span': events[-1].timestamp - events[0].timestamp if len(events) > 1 else 0,
            'avg_value': sum(e.value for e in events) / len(events)
        }
```

### ê°œìˆ˜ ê¸°ë°˜ ìœˆë„ìš° (Count-based Windows)

ë°ì´í„° ê°œìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìœˆë„ìš°ë¥¼ ì •ì˜í•˜ëŠ” ë°©ì‹ì´ë‹¤.

```python
class CountBasedWindow:
    def __init__(self, window_size):
        self.window_size = window_size
        self.data_buffer = deque(maxlen=window_size)
    
    def add_data(self, data):
        self.data_buffer.append(data)
        
        if len(self.data_buffer) == self.window_size:
            return self.process_full_window(list(self.data_buffer))
        return None
    
    def process_full_window(self, window_data):
        return {
            'count': len(window_data),
            'average': sum(window_data) / len(window_data),
            'max': max(window_data),
            'min': min(window_data),
            'std_dev': self.calculate_std_dev(window_data)
        }
    
    def calculate_std_dev(self, data):
        if len(data) < 2:
            return 0
        mean = sum(data) / len(data)
        variance = sum((x - mean) ** 2 for x in data) / len(data)
        return variance ** 0.5
```

### ì„¸ì…˜ ìœˆë„ìš° (Session Windows)

ì‚¬ìš©ì í™œë™ì´ë‚˜ ì„¸ì…˜ì„ ê¸°ì¤€ìœ¼ë¡œ ìœˆë„ìš°ë¥¼ ì •ì˜í•˜ëŠ” ë°©ì‹ì´ë‹¤.

```python
class SessionWindow:
    def __init__(self, session_timeout):
        self.session_timeout = session_timeout
        self.active_sessions = {}  # session_id -> (last_activity, events)
    
    def process_event(self, event):
        session_id = event.session_id
        current_time = event.timestamp
        
        if session_id in self.active_sessions:
            last_activity, events = self.active_sessions[session_id]
            
            # ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ í™•ì¸
            if current_time - last_activity > self.session_timeout:
                # ì„¸ì…˜ ì¢…ë£Œ ë° ì²˜ë¦¬
                self.process_session(session_id, events)
                events = []
            
            events.append(event)
            self.active_sessions[session_id] = (current_time, events)
        else:
            # ìƒˆ ì„¸ì…˜ ì‹œì‘
            self.active_sessions[session_id] = (current_time, [event])
    
    def process_session(self, session_id, events):
        print(f"ì„¸ì…˜ {session_id} ì²˜ë¦¬: {len(events)}ê°œ ì´ë²¤íŠ¸")
        return {
            'session_id': session_id,
            'event_count': len(events),
            'duration': events[-1].timestamp - events[0].timestamp if len(events) > 1 else 0
        }
```

## ì‹¤ì œ êµ¬í˜„ ì˜ˆì œ

### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

```python
import random
from datetime import datetime
import threading
import time

class RealTimeMonitor:
    def __init__(self, window_size=100):
        self.window_size = window_size
        self.data_window = deque(maxlen=window_size)
        self.alert_threshold = 2.0  # Z-score ì„ê³„ê°’
        self.lock = threading.Lock()
    
    def add_metric(self, metric_value):
        with self.lock:
            self.data_window.append(metric_value)
            
            if len(self.data_window) >= 10:  # ìµœì†Œ ë°ì´í„° í•„ìš”
                return self.detect_anomaly(metric_value)
        return False
    
    def detect_anomaly(self, current_value):
        values = list(self.data_window)
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / len(values)
        std_dev = variance ** 0.5
        
        if std_dev == 0:
            return False
        
        z_score = abs((current_value - mean) / std_dev)
        return z_score > self.alert_threshold
    
    def get_statistics(self):
        with self.lock:
            if not self.data_window:
                return {}
            
            values = list(self.data_window)
            return {
                'count': len(values),
                'average': sum(values) / len(values),
                'max': max(values),
                'min': min(values),
                'std_dev': self.calculate_std_dev(values)
            }
    
    def calculate_std_dev(self, values):
        if len(values) < 2:
            return 0
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / len(values)
        return variance ** 0.5

# ì‚¬ìš© ì˜ˆì‹œ
def simulate_monitoring():
    monitor = RealTimeMonitor(window_size=50)
    
    def generate_data():
        while True:
            # ì •ìƒ ë°ì´í„° (í‰ê·  100, í‘œì¤€í¸ì°¨ 10)
            value = random.normalvariate(100, 10)
            
            # ê°€ë” ì´ìƒê°’ ìƒì„±
            if random.random() < 0.05:  # 5% í™•ë¥ ë¡œ ì´ìƒê°’
                value = random.normalvariate(200, 20)
            
            is_anomaly = monitor.add_metric(value)
            
            if is_anomaly:
                print(f"ğŸš¨ ì´ìƒê°’ ê°ì§€: {value:.2f}")
            
            time.sleep(0.1)  # 100ms ê°„ê²©
    
    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë°ì´í„° ìƒì„±
    thread = threading.Thread(target=generate_data, daemon=True)
    thread.start()
    
    # ì£¼ê¸°ì ìœ¼ë¡œ í†µê³„ ì¶œë ¥
    while True:
        stats = monitor.get_statistics()
        if stats:
            print(f"ğŸ“Š í†µê³„: {stats}")
        time.sleep(5)
```

### ê¸ˆìœµ ê±°ë˜ ë¶„ì„

```python
from dataclasses import dataclass
from datetime import datetime

@dataclass
class Trade:
    timestamp: datetime
    symbol: str
    price: float
    volume: int
    trade_type: str  # 'buy' or 'sell'

class TradingAnalyzer:
    def __init__(self, time_window_minutes=5):
        self.time_window = time_window_minutes * 60  # ì´ˆ ë‹¨ìœ„
        self.trades = deque()
        self.volume_profile = {}  # ê°€ê²©ëŒ€ë³„ ê±°ë˜ëŸ‰
    
    def add_trade(self, trade):
        current_time = trade.timestamp
        
        # ìœˆë„ìš° ë°–ì˜ ê±°ë˜ ì œê±°
        while self.trades and self.trades[0].timestamp < current_time - self.time_window:
            old_trade = self.trades.popleft()
            self.update_volume_profile(old_trade, remove=True)
        
        self.trades.append(trade)
        self.update_volume_profile(trade, remove=False)
        
        return self.calculate_metrics()
    
    def update_volume_profile(self, trade, remove=False):
        price_level = round(trade.price, 2)  # ê°€ê²©ì„ 0.01 ë‹¨ìœ„ë¡œ ë°˜ì˜¬ë¦¼
        
        if price_level not in self.volume_profile:
            self.volume_profile[price_level] = 0
        
        if remove:
            self.volume_profile[price_level] -= trade.volume
            if self.volume_profile[price_level] <= 0:
                del self.volume_profile[price_level]
        else:
            self.volume_profile[price_level] += trade.volume
    
    def calculate_metrics(self):
        if not self.trades:
            return {}
        
        prices = [trade.price for trade in self.trades]
        volumes = [trade.volume for trade in self.trades]
        
        # ê±°ë˜ëŸ‰ ê°€ì¤‘ í‰ê·  ê°€ê²© (VWAP)
        total_value = sum(p * v for p, v in zip(prices, volumes))
        total_volume = sum(volumes)
        vwap = total_value / total_volume if total_volume > 0 else 0
        
        return {
            'vwap': vwap,
            'price_volatility': self.calculate_volatility(prices),
            'total_volume': total_volume,
            'trade_count': len(self.trades),
            'avg_trade_size': total_volume / len(self.trades) if self.trades else 0,
            'volume_profile': dict(sorted(self.volume_profile.items()))
        }
    
    def calculate_volatility(self, prices):
        if len(prices) < 2:
            return 0
        
        returns = [(prices[i] - prices[i-1]) / prices[i-1] for i in range(1, len(prices))]
        mean_return = sum(returns) / len(returns)
        variance = sum((r - mean_return) ** 2 for r in returns) / len(returns)
        return variance ** 0.5
```

### ì›¹ ë¡œê·¸ ë¶„ì„

```python
@dataclass
class WebRequest:
    timestamp: datetime
    ip_address: str
    method: str
    url: str
    status_code: int
    response_time: float
    user_agent: str

class WebLogAnalyzer:
    def __init__(self, window_minutes=10):
        self.window_minutes = window_minutes
        self.requests = deque()
        self.error_threshold = 0.1  # 10% ì—ëŸ¬ìœ¨ ì„ê³„ê°’
        self.response_time_threshold = 2.0  # 2ì´ˆ ì‘ë‹µì‹œê°„ ì„ê³„ê°’
    
    def add_request(self, request):
        current_time = request.timestamp
        
        # ìœˆë„ìš° ë°–ì˜ ìš”ì²­ ì œê±°
        while self.requests and self.requests[0].timestamp < current_time - self.window_minutes * 60:
            self.requests.popleft()
        
        self.requests.append(request)
        
        return self.analyze_performance()
    
    def analyze_performance(self):
        if not self.requests:
            return {}
        
        total_requests = len(self.requests)
        error_requests = sum(1 for req in self.requests if req.status_code >= 400)
        slow_requests = sum(1 for req in self.requests if req.response_time > self.response_time_threshold)
        
        error_rate = error_requests / total_requests
        slow_rate = slow_requests / total_requests
        
        # IPë³„ ìš”ì²­ ìˆ˜
        ip_counts = {}
        for req in self.requests:
            ip_counts[req.ip_address] = ip_counts.get(req.ip_address, 0) + 1
        
        # URLë³„ ìš”ì²­ ìˆ˜
        url_counts = {}
        for req in self.requests:
            url_counts[req.url] = url_counts.get(req.url, 0) + 1
        
        return {
            'request_rate': total_requests / (self.window_minutes * 60),  # ìš”ì²­/ì´ˆ
            'error_rate': error_rate,
            'slow_request_rate': slow_rate,
            'avg_response_time': sum(req.response_time for req in self.requests) / total_requests,
            'is_alert': error_rate > self.error_threshold or slow_rate > 0.2,
            'top_ips': sorted(ip_counts.items(), key=lambda x: x[1], reverse=True)[:5],
            'top_urls': sorted(url_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        }
```

## ì„±ëŠ¥ ìµœì í™” ì „ëµ

### ë©”ëª¨ë¦¬ ìµœì í™”

```python
class OptimizedWindow:
    def __init__(self, window_size):
        self.window_size = window_size
        self.sum = 0
        self.count = 0
        self.data = deque(maxlen=window_size)
    
    def add_value(self, value):
        if len(self.data) == self.window_size:
            # ìœˆë„ìš°ê°€ ê°€ë“ ì°¬ ê²½ìš°, ê°€ì¥ ì˜¤ë˜ëœ ê°’ ì œê±°
            old_value = self.data.popleft()
            self.sum -= old_value
            self.count -= 1
        
        self.data.append(value)
        self.sum += value
        self.count += 1
    
    def get_average(self):
        return self.sum / self.count if self.count > 0 else 0
    
    def get_statistics(self):
        if not self.data:
            return {}
        
        return {
            'count': self.count,
            'average': self.get_average(),
            'max': max(self.data),
            'min': min(self.data)
        }
```

### ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”

```python
from concurrent.futures import ThreadPoolExecutor
import threading

class ParallelWindowProcessor:
    def __init__(self, num_workers=4):
        self.executor = ThreadPoolExecutor(max_workers=num_workers)
        self.lock = threading.Lock()
        self.windows = {}
    
    def process_window(self, window_id, data):
        with self.lock:
            if window_id not in self.windows:
                self.windows[window_id] = []
            self.windows[window_id].extend(data)
        
        # ë³‘ë ¬ë¡œ ìœˆë„ìš° ì²˜ë¦¬
        future = self.executor.submit(self.analyze_window, window_id, data)
        return future
    
    def analyze_window(self, window_id, data):
        # ìœˆë„ìš° ë°ì´í„° ë¶„ì„ ë¡œì§
        return {
            'window_id': window_id,
            'count': len(data),
            'average': sum(data) / len(data) if data else 0,
            'processed_at': datetime.now()
        }
    
    def shutdown(self):
        self.executor.shutdown(wait=True)
```

### ì§€ì—° ë°ì´í„° ì²˜ë¦¬

```python
class LateDataHandler:
    def __init__(self, allowed_lateness_seconds=300):  # 5ë¶„ ì§€ì—° í—ˆìš©
        self.allowed_lateness = allowed_lateness_seconds
        self.pending_windows = {}
        self.window_duration = 60  # 1ë¶„ ìœˆë„ìš°
    
    def process_event(self, event):
        current_time = event.timestamp
        window_start = self.get_window_start(current_time)
        
        # ì§€ì—° ë°ì´í„° í™•ì¸
        if current_time < window_start - self.allowed_lateness:
            # ë„ˆë¬´ ì˜¤ë˜ëœ ë°ì´í„°ëŠ” ë¬´ì‹œ
            print(f"ì§€ì—° ë°ì´í„° ë¬´ì‹œ: {event}")
            return None
        
        # ìœˆë„ìš°ì— ë°ì´í„° ì¶”ê°€
        if window_start not in self.pending_windows:
            self.pending_windows[window_start] = []
        
        self.pending_windows[window_start].append(event)
        
        # ìœˆë„ìš° ì™„ë£Œ í™•ì¸
        if self.is_window_complete(window_start):
            return self.finalize_window(window_start)
    
    def get_window_start(self, timestamp):
        # ìœˆë„ìš° ì‹œì‘ ì‹œê°„ ê³„ì‚°
        return timestamp - (timestamp % self.window_duration)
    
    def is_window_complete(self, window_start):
        # ìœˆë„ìš° ì™„ë£Œ ì¡°ê±´ í™•ì¸
        current_time = time.time()
        return current_time >= window_start + self.window_duration + self.allowed_lateness
    
    def finalize_window(self, window_start):
        if window_start in self.pending_windows:
            data = self.pending_windows.pop(window_start)
            return self.process_window_data(data)
        return None
    
    def process_window_data(self, data):
        return {
            'window_data': data,
            'count': len(data),
            'processed_at': datetime.now()
        }
```

## ì‹¤ë¬´ ì ìš© ì‚¬ë¡€: Apache Kafka vs Apache Flink

Apache Kafkaì™€ Apache FlinkëŠ” ëª¨ë‘ ìŠ¤íŠ¸ë¦¼ ë°ì´í„° ì²˜ë¦¬ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ì§€ë§Œ, ê°ê° ë‹¤ë¥¸ ëª©ì ê³¼ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆë‹¤. ìœˆë„ì‰ ê¸°ë²• ê´€ì ì—ì„œ ë‘ í”Œë«í¼ì˜ ì°¨ì´ì ì„ ì‚´í´ë³´ì.

### Apache Kafka: ë©”ì‹œì§€ ë¸Œë¡œì»¤ (Message Broker)

**Kafkaì˜ í•µì‹¬ ì—­í• :**
- **ë°ì´í„° ì „ì†¡**: í”„ë¡œë“€ì„œì™€ ì»¨ìŠˆë¨¸ ê°„ì˜ ë©”ì‹œì§€ ì „ë‹¬
- **ë°ì´í„° ì €ì¥**: ë””ìŠ¤í¬ì— ë©”ì‹œì§€ë¥¼ ì˜êµ¬ ì €ì¥
- **í™•ì¥ì„±**: ìˆ˜í‰ì  í™•ì¥ìœ¼ë¡œ ë†’ì€ ì²˜ë¦¬ëŸ‰ ì§€ì›

**Kafkaì—ì„œì˜ ìœˆë„ì‰:**
```python
from kafka import KafkaConsumer, KafkaProducer
import json
import time
from collections import deque

class KafkaWindowProcessor:
    def __init__(self, bootstrap_servers, input_topic, output_topic):
        self.consumer = KafkaConsumer(
            input_topic,
            bootstrap_servers=bootstrap_servers,
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            auto_offset_reset='latest'
        )
        self.producer = KafkaProducer(
            bootstrap_servers=bootstrap_servers,
            value_serializer=lambda v: json.dumps(v).encode('utf-8')
        )
        self.output_topic = output_topic
        
        # KafkaëŠ” ìì²´ ìœˆë„ì‰ ê¸°ëŠ¥ì´ ì—†ìœ¼ë¯€ë¡œ ì§ì ‘ êµ¬í˜„
        self.window_data = deque(maxlen=1000)  # ìµœëŒ€ 1000ê°œ ë©”ì‹œì§€
        self.window_start_time = None
        self.window_duration = 300  # 5ë¶„ ìœˆë„ìš°
    
    def process_messages(self):
        for message in self.consumer:
            event = {
                'timestamp': message.value.get('timestamp', time.time()),
                'value': message.value.get('value', 0),
                'source': message.value.get('source', 'unknown')
            }
            
            result = self.process_with_window(event)
            if result:
                # ìœˆë„ìš° ì²˜ë¦¬ ê²°ê³¼ë¥¼ ì¶œë ¥ í† í”½ìœ¼ë¡œ ì „ì†¡
                self.producer.send(self.output_topic, result)
                print(f"ìœˆë„ìš° ì²˜ë¦¬ ê²°ê³¼ ì „ì†¡: {result}")
    
    def process_with_window(self, event):
        current_time = event['timestamp']
        
        # ìœˆë„ìš° ì‹œì‘ ì‹œê°„ ì„¤ì •
        if self.window_start_time is None:
            self.window_start_time = current_time
        
        # ìœˆë„ìš°ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
        if current_time >= self.window_start_time + self.window_duration:
            # ìœˆë„ìš° ì²˜ë¦¬
            result = self.process_window()
            
            # ìƒˆ ìœˆë„ìš° ì‹œì‘
            self.window_start_time = current_time
            self.window_data.clear()
            self.window_data.append(event)
            
            return result
        else:
            # ìœˆë„ìš°ì— ë°ì´í„° ì¶”ê°€
            self.window_data.append(event)
            return None
    
    def process_window(self):
        if not self.window_data:
            return None
        
        values = [event['value'] for event in self.window_data]
        return {
            'window_start': self.window_start_time,
            'window_end': self.window_start_time + self.window_duration,
            'count': len(values),
            'average': sum(values) / len(values),
            'max': max(values),
            'min': min(values)
        }
    
    def close(self):
        self.consumer.close()
        self.producer.close()
```

**Kafkaì˜ ìœˆë„ì‰ íŠ¹ì§•:**
- âŒ **ìì²´ ìœˆë„ì‰ ê¸°ëŠ¥ ì—†ìŒ**: ê°œë°œìê°€ ì§ì ‘ êµ¬í˜„í•´ì•¼ í•¨
- âœ… **ë†’ì€ ì²˜ë¦¬ëŸ‰**: ì´ˆë‹¹ ìˆ˜ì‹­ë§Œ ë©”ì‹œì§€ ì²˜ë¦¬ ê°€ëŠ¥
- âœ… **ë‚´êµ¬ì„±**: ë””ìŠ¤í¬ ì €ì¥ìœ¼ë¡œ ë°ì´í„° ì†ì‹¤ ë°©ì§€
- âŒ **ë³µì¡í•œ ìœˆë„ì‰ ë¡œì§**: ìƒíƒœ ê´€ë¦¬, ì›Œí„°ë§ˆí¬ ë“± ì§ì ‘ êµ¬í˜„

### Apache Flink: ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì—”ì§„ (Stream Processing Engine)

**Flinkì˜ í•µì‹¬ ì—­í• :**
- **ë°ì´í„° ì²˜ë¦¬**: ë³µì¡í•œ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ë¡œì§ ì‹¤í–‰
- **ìœˆë„ì‰**: ë‚´ì¥ëœ ë‹¤ì–‘í•œ ìœˆë„ì‰ ê¸°ëŠ¥ ì œê³µ
- **ìƒíƒœ ê´€ë¦¬**: ë¶„ì‚° í™˜ê²½ì—ì„œ ìƒíƒœë¥¼ ì•ˆì „í•˜ê²Œ ê´€ë¦¬

**Flinkì—ì„œì˜ ìœˆë„ì‰:**
```python
# Flink ìœˆë„ì‰ ì˜ˆì‹œ (Python API)
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.datastream.window import TimeWindow, CountWindow, SessionWindow
from pyflink.common.time import Time
from pyflink.datastream.functions import WindowFunction
from pyflink.common.typeinfo import Types

class FlinkWindowingExample:
    def __init__(self):
        self.env = StreamExecutionEnvironment.get_execution_environment()
        self.env.set_parallelism(4)  # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
    
    def run_time_windowing(self):
        """ì‹œê°„ ê¸°ë°˜ ìœˆë„ì‰"""
        # ì†Œì¼“ì—ì„œ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ ì½ê¸°
        stream = self.env.socket_text_stream("localhost", 9999)
        
        # ë°ì´í„° íŒŒì‹±
        parsed_stream = stream.map(
            lambda x: self.parse_event(x),
            output_type=Types.ROW([Types.STRING(), Types.DOUBLE(), Types.LONG()])
        )
        
        # ì‹œê°„ ê¸°ë°˜ ìœˆë„ìš° (5ì´ˆ)
        time_windowed = parsed_stream \
            .key_by(lambda x: x[0]) \
            .window(TimeWindow.of(Time.seconds(5))) \
            .apply(self.process_time_window)
        
        time_windowed.print("Time Window Results")
        return time_windowed
    
    def run_count_windowing(self):
        """ê°œìˆ˜ ê¸°ë°˜ ìœˆë„ì‰"""
        stream = self.env.socket_text_stream("localhost", 9999)
        parsed_stream = stream.map(
            lambda x: self.parse_event(x),
            output_type=Types.ROW([Types.STRING(), Types.DOUBLE(), Types.LONG()])
        )
        
        # ê°œìˆ˜ ê¸°ë°˜ ìœˆë„ìš° (100ê°œ)
        count_windowed = parsed_stream \
            .key_by(lambda x: x[0]) \
            .count_window(100) \
            .apply(self.process_count_window)
        
        count_windowed.print("Count Window Results")
        return count_windowed
    
    def run_session_windowing(self):
        """ì„¸ì…˜ ìœˆë„ì‰"""
        stream = self.env.socket_text_stream("localhost", 9999)
        parsed_stream = stream.map(
            lambda x: self.parse_event(x),
            output_type=Types.ROW([Types.STRING(), Types.DOUBLE(), Types.LONG()])
        )
        
        # ì„¸ì…˜ ìœˆë„ìš° (30ì´ˆ íƒ€ì„ì•„ì›ƒ)
        session_windowed = parsed_stream \
            .key_by(lambda x: x[0]) \
            .window(SessionWindow.with_gap(Time.seconds(30))) \
            .apply(self.process_session_window)
        
        session_windowed.print("Session Window Results")
        return session_windowed
    
    def parse_event(self, line):
        """ì´ë²¤íŠ¸ íŒŒì‹±"""
        parts = line.split(',')
        return (parts[0], float(parts[1]), int(parts[2]))
    
    def process_time_window(self, key, window, events):
        """ì‹œê°„ ìœˆë„ìš° ì²˜ë¦¬"""
        values = [event[1] for event in events]
        return {
            'window_type': 'time',
            'key': key,
            'window_start': window.get_start(),
            'window_end': window.get_end(),
            'count': len(values),
            'average': sum(values) / len(values) if values else 0,
            'max': max(values) if values else 0,
            'min': min(values) if values else 0
        }
    
    def process_count_window(self, key, window, events):
        """ê°œìˆ˜ ìœˆë„ìš° ì²˜ë¦¬"""
        values = [event[1] for event in events]
        return {
            'window_type': 'count',
            'key': key,
            'window_id': window.get_id(),
            'count': len(values),
            'average': sum(values) / len(values) if values else 0
        }
    
    def process_session_window(self, key, window, events):
        """ì„¸ì…˜ ìœˆë„ìš° ì²˜ë¦¬"""
        values = [event[1] for event in events]
        return {
            'window_type': 'session',
            'key': key,
            'session_start': window.get_start(),
            'session_end': window.get_end(),
            'session_duration': window.get_end() - window.get_start(),
            'count': len(values),
            'average': sum(values) / len(values) if values else 0
        }
    
    def execute(self):
        """ëª¨ë“  ìœˆë„ì‰ ì˜ˆì œ ì‹¤í–‰"""
        self.run_time_windowing()
        self.run_count_windowing()
        self.run_session_windowing()
        self.env.execute("Flink Windowing Examples")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    flink_example = FlinkWindowingExample()
    flink_example.execute()
```

**Flinkì˜ ìœˆë„ì‰ íŠ¹ì§•:**
- âœ… **ë‚´ì¥ ìœˆë„ì‰ ê¸°ëŠ¥**: ì‹œê°„, ê°œìˆ˜, ì„¸ì…˜ ìœˆë„ìš° ë“± ë‹¤ì–‘í•œ ìœ í˜• ì§€ì›
- âœ… **ì›Œí„°ë§ˆí¬**: ì§€ì—° ë°ì´í„° ì²˜ë¦¬ì™€ ìœˆë„ìš° ì™„ë£Œ ë³´ì¥
- âœ… **ìƒíƒœ ê´€ë¦¬**: ì²´í¬í¬ì¸íŠ¸ì™€ ìƒíƒœ ë°±ì—…ìœ¼ë¡œ ì¥ì•  ë³µêµ¬
- âœ… **ë³µì¡í•œ ì—°ì‚°**: ì¡°ì¸, ì§‘ê³„, íŒ¨í„´ ë§¤ì¹­ ë“± ê³ ê¸‰ ê¸°ëŠ¥
- âŒ **ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ ì²˜ë¦¬ëŸ‰**: ë³µì¡í•œ ì²˜ë¦¬ë¡œ ì¸í•œ ì˜¤ë²„í—¤ë“œ

### Kafka vs Flink ë¹„êµí‘œ

| **íŠ¹ì§•** | **Apache Kafka** | **Apache Flink** |
|---------|-----------------|------------------|
| **ì£¼ìš” ì—­í• ** | ë©”ì‹œì§€ ë¸Œë¡œì»¤ | ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì—”ì§„ |
| **ìœˆë„ì‰ ê¸°ëŠ¥** | âŒ ì§ì ‘ êµ¬í˜„ í•„ìš” | âœ… ë‚´ì¥ ê¸°ëŠ¥ ì œê³µ |
| **ì²˜ë¦¬ëŸ‰** | ë§¤ìš° ë†’ìŒ (ìˆ˜ì‹­ë§Œ/ì´ˆ) | ë†’ìŒ (ìˆ˜ë§Œ/ì´ˆ) |
| **ì§€ì—° ì‹œê°„** | ë§¤ìš° ë‚®ìŒ (ë°€ë¦¬ì´ˆ) | ë‚®ìŒ (ì´ˆ ë‹¨ìœ„) |
| **ìƒíƒœ ê´€ë¦¬** | âŒ ì§ì ‘ êµ¬í˜„ | âœ… ë‚´ì¥ ê¸°ëŠ¥ |
| **ì¥ì•  ë³µêµ¬** | âœ… ìë™ ë³µêµ¬ | âœ… ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ |
| **í™•ì¥ì„±** | ë§¤ìš° ë†’ìŒ | ë†’ìŒ |
| **ë³µì¡í•œ ì—°ì‚°** | âŒ ì œí•œì  | âœ… í’ë¶€í•œ ê¸°ëŠ¥ |
| **í•™ìŠµ ê³¡ì„ ** | ë‚®ìŒ | ë†’ìŒ |

### ì‹¤ì œ ì•„í‚¤í…ì²˜ì—ì„œì˜ í™œìš©

**Kafka + Flink ì¡°í•© (ê¶Œì¥):**
```python
# Kafkaë¡œ ë°ì´í„° ìˆ˜ì§‘, Flinkë¡œ ì²˜ë¦¬í•˜ëŠ” ì•„í‚¤í…ì²˜
class KafkaFlinkArchitecture:
    def __init__(self):
        self.kafka_source = KafkaConsumer(
            'raw-data-topic',
            bootstrap_servers=['localhost:9092'],
            value_deserializer=lambda m: json.loads(m.decode('utf-8'))
        )
        
        # Flink í™˜ê²½ ì„¤ì •
        self.env = StreamExecutionEnvironment.get_execution_environment()
        self.env.set_parallelism(4)
    
    def create_flink_kafka_source(self):
        """Kafkaë¥¼ Flink ì†ŒìŠ¤ë¡œ ì‚¬ìš©"""
        return self.env \
            .add_source(self.kafka_source) \
            .map(lambda x: self.parse_event(x))
    
    def process_with_flink_windowing(self):
        """Flink ìœˆë„ì‰ìœ¼ë¡œ ì²˜ë¦¬"""
        stream = self.create_flink_kafka_source()
        
        # ë³µì¡í•œ ìœˆë„ì‰ ì²˜ë¦¬
        processed = stream \
            .key_by(lambda x: x['key']) \
            .window(TimeWindow.of(Time.seconds(60))) \
            .apply(self.complex_window_function)
        
        return processed
    
    def complex_window_function(self, key, window, events):
        """ë³µì¡í•œ ìœˆë„ìš° í•¨ìˆ˜"""
        # í†µê³„ ê³„ì‚°
        values = [event['value'] for event in events]
        
        # ì´ìƒê°’ íƒì§€
        mean = sum(values) / len(values)
        std_dev = (sum((x - mean) ** 2 for x in values) / len(values)) ** 0.5
        
        anomalies = [v for v in values if abs(v - mean) > 2 * std_dev]
        
        return {
            'key': key,
            'window_start': window.get_start(),
            'window_end': window.get_end(),
            'count': len(values),
            'average': mean,
            'std_dev': std_dev,
            'anomaly_count': len(anomalies),
            'anomalies': anomalies
        }
```

**ê²°ë¡ :**
- **Kafka**: ë°ì´í„° ì „ì†¡ê³¼ ì €ì¥ì— íŠ¹í™”, ë†’ì€ ì²˜ë¦¬ëŸ‰ê³¼ ë‚®ì€ ì§€ì—° ì‹œê°„
- **Flink**: ë³µì¡í•œ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ì™€ ìœˆë„ì‰ì— íŠ¹í™”, í’ë¶€í•œ ë¶„ì„ ê¸°ëŠ¥
- **ì‹¤ë¬´**: Kafkaë¡œ ë°ì´í„° ìˆ˜ì§‘ â†’ Flinkë¡œ ì²˜ë¦¬í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ê°€ ì¼ë°˜ì 

## ê²°ë¡ 

ìœˆë„ì‰ ê¸°ë²•ì€ í˜„ëŒ€ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œì—ì„œ í•„ìˆ˜ì ì¸ ê¸°ìˆ ì´ë‹¤. ì‹œê°„ ê¸°ë°˜, ê°œìˆ˜ ê¸°ë°˜, ì„¸ì…˜ ê¸°ë°˜ ë“± ë‹¤ì–‘í•œ ìœˆë„ìš° ìœ í˜•ì„ ìƒí™©ì— ë§ê²Œ ì„ íƒí•˜ê³ , ë©”ëª¨ë¦¬ ìµœì í™”ì™€ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•´ íš¨ìœ¨ì ì¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤.

ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§, ê¸ˆìœµ ê±°ë˜ ë¶„ì„, ì›¹ ë¡œê·¸ ë¶„ì„ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ìœˆë„ì‰ ê¸°ë²•ì´ í™œìš©ë˜ê³  ìˆìœ¼ë©°, AI/MLê³¼ì˜ í†µí•©, ì—£ì§€ ì»´í“¨íŒ…ê³¼ì˜ ê²°í•©ì„ í†µí•´ ë”ìš± ë°œì „í•  ê²ƒì´ë‹¤.

ìœˆë„ì‰ ê¸°ë²•ì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ë„ë©”ì¸ì— ë§ëŠ” ì ì ˆí•œ ìœˆë„ìš° ìœ í˜• ì„ íƒ, ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥ ìµœì í™”, ì§€ì—° ë°ì´í„° ì²˜ë¦¬ ì „ëµ ìˆ˜ë¦½ì´ ì¤‘ìš”í•˜ë‹¤. ì´ëŸ¬í•œ ìš”ì†Œë“¤ì„ ê³ ë ¤í•˜ì—¬ ì„¤ê³„ëœ ìœˆë„ì‰ ì‹œìŠ¤í…œì€ ëŒ€ìš©ëŸ‰ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë„êµ¬ê°€ ë  ê²ƒì´ë‹¤.

## ì°¸ê³  ìë£Œ

1. **Apache Flink ê³µì‹ ë¬¸ì„œ**: [Windowing](https://nightlies.apache.org/flink/flink-docs-stable/docs/dev/datastream/operators/windows/)
2. **Apache Kafka Streams**: [Windowing](https://kafka.apache.org/documentation/streams/)
3. **Apache Spark Streaming**: [Window Operations](https://spark.apache.org/docs/latest/streaming-programming-guide.html#window-operations)
4. **Google Cloud Dataflow**: [Windowing](https://cloud.google.com/dataflow/docs/concepts/streaming-pipelines#windowing)
5. **AWS Kinesis**: [Windowing](https://docs.aws.amazon.com/kinesisanalytics/latest/dev/windowing-concepts.html)
6. **ë„¤ì´ë²„ D2**: [ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ì™€ ìœˆë„ì‰ ê¸°ë²•](https://d2.naver.com/helloworld/1450243)
