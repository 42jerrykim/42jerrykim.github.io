---
draft: true
title: "17. ë™ì‹œì„± í”„ë¡œê·¸ë˜ë°"
description: "ë©€í‹°ìŠ¤ë ˆë”©ê³¼ ë©€í‹°í”„ë¡œì„¸ì‹±ì„ í™œìš©í•œ ë³‘ë ¬ ì²˜ë¦¬"
collection_order: 17
---

# ì±•í„° 17: ë™ì‹œì„± í”„ë¡œê·¸ë˜ë°

> "ë™ì‹œì— ì—¬ëŸ¬ ì¼ì„ ì²˜ë¦¬í•˜ë¼" - í˜„ëŒ€ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤.

## í•™ìŠµ ëª©í‘œ
- ë™ì‹œì„±ê³¼ ë³‘ë ¬ì„±ì˜ ì°¨ì´ë¥¼ ì´í•´í•  ìˆ˜ ìˆë‹¤
- ë©€í‹°ìŠ¤ë ˆë”©ê³¼ ë©€í‹°í”„ë¡œì„¸ì‹±ì„ ì ì ˆíˆ ì„ íƒí•  ìˆ˜ ìˆë‹¤
- ìŠ¤ë ˆë“œì™€ í”„ë¡œì„¸ìŠ¤ ê°„ í†µì‹ ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤
- ë™ì‹œì„± ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤

## ë™ì‹œì„± ê¸°ë³¸ ê°œë…

### 1. ë™ì‹œì„± vs ë³‘ë ¬ì„±

```python
import time
import threading
import multiprocessing

# ìˆœì°¨ ì‹¤í–‰
def sequential_task():
    print("=== ìˆœì°¨ ì‹¤í–‰ ===")
    start_time = time.time()
    
    def cpu_bound_task(n):
        result = 0
        for i in range(n):
            result += i * i
        return result
    
    # 4ê°œ ì‘ì—…ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰
    results = []
    for i in range(4):
        result = cpu_bound_task(1000000)
        results.append(result)
    
    end_time = time.time()
    print(f"ìˆœì°¨ ì‹¤í–‰ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    return results

# ë™ì‹œ ì‹¤í–‰ (ìŠ¤ë ˆë”©) - ë™ì‹œì„±
def concurrent_task():
    print("\n=== ë™ì‹œ ì‹¤í–‰ (ìŠ¤ë ˆë”©) ===")
    start_time = time.time()
    
    def cpu_bound_task(n):
        result = 0
        for i in range(n):
            result += i * i
        return result
    
    # ìŠ¤ë ˆë“œë¡œ ì‹¤í–‰
    threads = []
    results = [None] * 4
    
    def worker(index, n):
        results[index] = cpu_bound_task(n)
    
    for i in range(4):
        thread = threading.Thread(target=worker, args=(i, 1000000))
        threads.append(thread)
        thread.start()
    
    for thread in threads:
        thread.join()
    
    end_time = time.time()
    print(f"ìŠ¤ë ˆë”© ì‹¤í–‰ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    return results

# ë³‘ë ¬ ì‹¤í–‰ (í”„ë¡œì„¸ì‹±) - ì§„ì •í•œ ë³‘ë ¬ì„±
def parallel_task():
    print("\n=== ë³‘ë ¬ ì‹¤í–‰ (í”„ë¡œì„¸ì‹±) ===")
    start_time = time.time()
    
    def cpu_bound_task(n):
        result = 0
        for i in range(n):
            result += i * i
        return result
    
    # í”„ë¡œì„¸ìŠ¤ í’€ë¡œ ì‹¤í–‰
    with multiprocessing.Pool(processes=4) as pool:
        results = pool.map(cpu_bound_task, [1000000] * 4)
    
    end_time = time.time()
    print(f"í”„ë¡œì„¸ì‹± ì‹¤í–‰ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    return results

# ì„±ëŠ¥ ë¹„êµ
if __name__ == "__main__":
    sequential_task()
    concurrent_task()
    parallel_task()
```

### 2. GIL (Global Interpreter Lock) ì´í•´

```python
import threading
import time

# GILì˜ ì˜í–¥ì„ ë³´ì—¬ì£¼ëŠ” ì˜ˆì œ
def demonstrate_gil():
    print("=== GIL ì˜í–¥ ë°ëª¨ ===")
    
    # CPU ì§‘ì•½ì  ì‘ì—…
    def cpu_intensive():
        total = 0
        for i in range(10000000):
            total += i * i
        return total
    
    # I/O ì§‘ì•½ì  ì‘ì—…
    def io_intensive():
        for _ in range(10):
            time.sleep(0.1)  # I/O ëŒ€ê¸° ì‹œë®¬ë ˆì´ì…˜
        return "IO complete"
    
    # CPU ì§‘ì•½ì  ì‘ì—… - ìŠ¤ë ˆë”© vs ìˆœì°¨
    print("\n1. CPU ì§‘ì•½ì  ì‘ì—…:")
    
    # ìˆœì°¨ ì‹¤í–‰
    start = time.time()
    for _ in range(2):
        cpu_intensive()
    sequential_cpu_time = time.time() - start
    print(f"ìˆœì°¨ ì‹¤í–‰: {sequential_cpu_time:.2f}ì´ˆ")
    
    # ìŠ¤ë ˆë”© ì‹¤í–‰ (GIL ë•Œë¬¸ì— ë³„ë¡œ ë¹¨ë¼ì§€ì§€ ì•ŠìŒ)
    start = time.time()
    threads = []
    for _ in range(2):
        thread = threading.Thread(target=cpu_intensive)
        threads.append(thread)
        thread.start()
    
    for thread in threads:
        thread.join()
    
    threading_cpu_time = time.time() - start
    print(f"ìŠ¤ë ˆë”© ì‹¤í–‰: {threading_cpu_time:.2f}ì´ˆ")
    print(f"CPU ì‘ì—… ì„±ëŠ¥ ê°œì„ : {sequential_cpu_time / threading_cpu_time:.2f}ë°°")
    
    # I/O ì§‘ì•½ì  ì‘ì—… - ìŠ¤ë ˆë”© vs ìˆœì°¨
    print("\n2. I/O ì§‘ì•½ì  ì‘ì—…:")
    
    # ìˆœì°¨ ì‹¤í–‰
    start = time.time()
    for _ in range(5):
        io_intensive()
    sequential_io_time = time.time() - start
    print(f"ìˆœì°¨ ì‹¤í–‰: {sequential_io_time:.2f}ì´ˆ")
    
    # ìŠ¤ë ˆë”© ì‹¤í–‰ (I/O ëŒ€ê¸° ì¤‘ GIL í•´ì œë˜ì–´ ë¹¨ë¼ì§)
    start = time.time()
    threads = []
    for _ in range(5):
        thread = threading.Thread(target=io_intensive)
        threads.append(thread)
        thread.start()
    
    for thread in threads:
        thread.join()
    
    threading_io_time = time.time() - start
    print(f"ìŠ¤ë ˆë”© ì‹¤í–‰: {threading_io_time:.2f}ì´ˆ")
    print(f"I/O ì‘ì—… ì„±ëŠ¥ ê°œì„ : {sequential_io_time / threading_io_time:.2f}ë°°")

demonstrate_gil()
```

## ë©€í‹°ìŠ¤ë ˆë”© (threading)

### 1. ê¸°ë³¸ ìŠ¤ë ˆë“œ ìƒì„±ê³¼ ê´€ë¦¬

```python
import threading
import time
import random

class WorkerThread(threading.Thread):
    """ì»¤ìŠ¤í…€ ì›Œì»¤ ìŠ¤ë ˆë“œ"""
    
    def __init__(self, thread_id, name, work_time):
        threading.Thread.__init__(self)
        self.thread_id = thread_id
        self.name = name
        self.work_time = work_time
    
    def run(self):
        """ìŠ¤ë ˆë“œê°€ ì‹¤í–‰í•  ì‘ì—…"""
        print(f"ìŠ¤ë ˆë“œ {self.name} ì‹œì‘")
        for i in range(5):
            print(f"{self.name}: ì‘ì—… {i+1}/5 ìˆ˜í–‰ ì¤‘...")
            time.sleep(self.work_time)
        print(f"ìŠ¤ë ˆë“œ {self.name} ì™„ë£Œ")

# ì—¬ëŸ¬ ìŠ¤ë ˆë“œ ìƒì„± ë° ì‹¤í–‰
def thread_management_demo():
    print("=== ìŠ¤ë ˆë“œ ê´€ë¦¬ ë°ëª¨ ===")
    
    threads = []
    
    # 3ê°œì˜ ì›Œì»¤ ìŠ¤ë ˆë“œ ìƒì„±
    for i in range(3):
        worker_name = f"Worker-{i+1}"
        work_time = random.uniform(0.5, 1.5)
        thread = WorkerThread(i+1, worker_name, work_time)
        threads.append(thread)
    
    # ëª¨ë“  ìŠ¤ë ˆë“œ ì‹œì‘
    start_time = time.time()
    for thread in threads:
        thread.start()
    
    # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
    for thread in threads:
        thread.join()
    
    end_time = time.time()
    print(f"ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ. ì´ ì†Œìš”ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")

thread_management_demo()
```

### 2. ìŠ¤ë ˆë“œ ë™ê¸°í™”

```python
import threading
import time
import random

# ê³µìœ  ìì›
shared_resource = 0
lock = threading.Lock()

def unsafe_increment():
    """Lock ì—†ëŠ” ìœ„í—˜í•œ ì¦ê°€ í•¨ìˆ˜"""
    global shared_resource
    for _ in range(100000):
        shared_resource += 1

def safe_increment():
    """Lockì„ ì‚¬ìš©í•œ ì•ˆì „í•œ ì¦ê°€ í•¨ìˆ˜"""
    global shared_resource
    for _ in range(100000):
        with lock:
            shared_resource += 1

def demonstrate_thread_safety():
    """ìŠ¤ë ˆë“œ ì•ˆì „ì„± ë°ëª¨"""
    global shared_resource
    
    print("=== ìŠ¤ë ˆë“œ ì•ˆì „ì„± ë°ëª¨ ===")
    
    # 1. ìœ„í—˜í•œ ë°©ë²• (Race Condition ë°œìƒ ê°€ëŠ¥)
    print("\n1. Lock ì—†ì´ ì‹¤í–‰ (Race Condition):")
    shared_resource = 0
    
    threads = []
    for _ in range(5):
        thread = threading.Thread(target=unsafe_increment)
        threads.append(thread)
        thread.start()
    
    for thread in threads:
        thread.join()
    
    print(f"ê¸°ëŒ€ê°’: 500000, ì‹¤ì œê°’: {shared_resource}")
    
    # 2. ì•ˆì „í•œ ë°©ë²• (Lock ì‚¬ìš©)
    print("\n2. Lock ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰:")
    shared_resource = 0
    
    threads = []
    for _ in range(5):
        thread = threading.Thread(target=safe_increment)
        threads.append(thread)
        thread.start()
    
    for thread in threads:
        thread.join()
    
    print(f"ê¸°ëŒ€ê°’: 500000, ì‹¤ì œê°’: {shared_resource}")

demonstrate_thread_safety()
```

### 3. ìƒì‚°ì-ì†Œë¹„ì íŒ¨í„´

```python
import threading
import queue
import time
import random

def producer_consumer_demo():
    """ìƒì‚°ì-ì†Œë¹„ì íŒ¨í„´ ë°ëª¨"""
    print("\n=== ìƒì‚°ì-ì†Œë¹„ì íŒ¨í„´ ===")
    
    # ì‘ì—… í (ìŠ¤ë ˆë“œ ì•ˆì „)
    work_queue = queue.Queue(maxsize=10)
    
    # ì¢…ë£Œ ì‹ í˜¸
    shutdown_event = threading.Event()
    
    def producer(name, num_items):
        """ìƒì‚°ì ìŠ¤ë ˆë“œ"""
        for i in range(num_items):
            if shutdown_event.is_set():
                break
            
            item = f"{name}-item-{i+1}"
            work_queue.put(item)
            print(f"ìƒì‚°ì {name}: {item} ìƒì‚°")
            time.sleep(random.uniform(0.1, 0.5))
        
        print(f"ìƒì‚°ì {name} ì™„ë£Œ")
    
    def consumer(name):
        """ì†Œë¹„ì ìŠ¤ë ˆë“œ"""
        while not shutdown_event.is_set():
            try:
                # 1ì´ˆ timeoutìœ¼ë¡œ ì•„ì´í…œ ê°€ì ¸ì˜¤ê¸°
                item = work_queue.get(timeout=1)
                print(f"ì†Œë¹„ì {name}: {item} ì²˜ë¦¬ ì¤‘...")
                time.sleep(random.uniform(0.2, 0.8))
                work_queue.task_done()
                print(f"ì†Œë¹„ì {name}: {item} ì²˜ë¦¬ ì™„ë£Œ")
            except queue.Empty:
                continue
        
        print(f"ì†Œë¹„ì {name} ì¢…ë£Œ")
    
    # ìƒì‚°ì ìŠ¤ë ˆë“œë“¤
    producers = []
    for i in range(2):
        producer_thread = threading.Thread(
            target=producer, 
            args=(f"Producer-{i+1}", 5)
        )
        producers.append(producer_thread)
        producer_thread.start()
    
    # ì†Œë¹„ì ìŠ¤ë ˆë“œë“¤
    consumers = []
    for i in range(3):
        consumer_thread = threading.Thread(
            target=consumer,
            args=(f"Consumer-{i+1}",)
        )
        consumers.append(consumer_thread)
        consumer_thread.daemon = True  # ë©”ì¸ ì¢…ë£Œ ì‹œ ê°™ì´ ì¢…ë£Œ
        consumer_thread.start()
    
    # ëª¨ë“  ìƒì‚°ì ì™„ë£Œ ëŒ€ê¸°
    for producer_thread in producers:
        producer_thread.join()
    
    # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
    work_queue.join()
    
    # ì†Œë¹„ìë“¤ì—ê²Œ ì¢…ë£Œ ì‹ í˜¸
    shutdown_event.set()
    
    print("ìƒì‚°ì-ì†Œë¹„ì ë°ëª¨ ì™„ë£Œ")

producer_consumer_demo()
```

## ë©€í‹°í”„ë¡œì„¸ì‹± (multiprocessing)

### 1. ê¸°ë³¸ í”„ë¡œì„¸ìŠ¤ ìƒì„±

```python
import multiprocessing
import time
import os

def worker_process(name, work_time):
    """ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ í•¨ìˆ˜"""
    print(f"í”„ë¡œì„¸ìŠ¤ {name} ì‹œì‘ (PID: {os.getpid()})")
    
    # CPU ì§‘ì•½ì  ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
    total = 0
    for i in range(1000000):
        total += i * i
    
    print(f"í”„ë¡œì„¸ìŠ¤ {name} ì™„ë£Œ (PID: {os.getpid()})")
    return total

def multiprocessing_demo():
    """ë©€í‹°í”„ë¡œì„¸ì‹± ê¸°ë³¸ ë°ëª¨"""
    print("=== ë©€í‹°í”„ë¡œì„¸ì‹± ë°ëª¨ ===")
    print(f"ë©”ì¸ í”„ë¡œì„¸ìŠ¤ PID: {os.getpid()}")
    
    # í”„ë¡œì„¸ìŠ¤ ë¦¬ìŠ¤íŠ¸
    processes = []
    
    # 4ê°œì˜ ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ìƒì„±
    for i in range(4):
        process = multiprocessing.Process(
            target=worker_process,
            args=(f"Worker-{i+1}", 1)
        )
        processes.append(process)
    
    # ëª¨ë“  í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    start_time = time.time()
    for process in processes:
        process.start()
    
    # ëª¨ë“  í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ëŒ€ê¸°
    for process in processes:
        process.join()
    
    end_time = time.time()
    print(f"ëª¨ë“  í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ. ì†Œìš”ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")

if __name__ == "__main__":
    multiprocessing_demo()
```

### 2. í”„ë¡œì„¸ìŠ¤ ê°„ í†µì‹ 

```python
import multiprocessing
import time
import random

def queue_communication():
    """íë¥¼ ì´ìš©í•œ í”„ë¡œì„¸ìŠ¤ ê°„ í†µì‹ """
    print("\n=== í í†µì‹  ë°ëª¨ ===")
    
    def producer_process(queue, name, count):
        """ìƒì‚°ì í”„ë¡œì„¸ìŠ¤"""
        for i in range(count):
            item = f"{name}-item-{i+1}"
            queue.put(item)
            print(f"ìƒì‚°ì {name}: {item} ìƒì‚°")
            time.sleep(random.uniform(0.1, 0.3))
        
        # ì¢…ë£Œ ì‹ í˜¸
        queue.put(None)
        print(f"ìƒì‚°ì {name} ì™„ë£Œ")
    
    def consumer_process(queue, name):
        """ì†Œë¹„ì í”„ë¡œì„¸ìŠ¤"""
        while True:
            item = queue.get()
            if item is None:
                break
            
            print(f"ì†Œë¹„ì {name}: {item} ì²˜ë¦¬ ì¤‘...")
            time.sleep(random.uniform(0.2, 0.5))
            print(f"ì†Œë¹„ì {name}: {item} ì²˜ë¦¬ ì™„ë£Œ")
        
        print(f"ì†Œë¹„ì {name} ì™„ë£Œ")
    
    # í ìƒì„±
    comm_queue = multiprocessing.Queue()
    
    # í”„ë¡œì„¸ìŠ¤ ìƒì„±
    producer = multiprocessing.Process(
        target=producer_process,
        args=(comm_queue, "Producer", 5)
    )
    
    consumer = multiprocessing.Process(
        target=consumer_process,
        args=(comm_queue, "Consumer")
    )
    
    # í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    producer.start()
    consumer.start()
    
    # ì™„ë£Œ ëŒ€ê¸°
    producer.join()
    consumer.join()

def pipe_communication():
    """íŒŒì´í”„ë¥¼ ì´ìš©í•œ í”„ë¡œì„¸ìŠ¤ ê°„ í†µì‹ """
    print("\n=== íŒŒì´í”„ í†µì‹  ë°ëª¨ ===")
    
    def sender_process(conn, name):
        """ì†¡ì‹ ì í”„ë¡œì„¸ìŠ¤"""
        for i in range(5):
            message = f"Message {i+1} from {name}"
            conn.send(message)
            print(f"ì†¡ì‹ : {message}")
            time.sleep(0.5)
        
        conn.close()
        print(f"ì†¡ì‹ ì {name} ì™„ë£Œ")
    
    def receiver_process(conn, name):
        """ìˆ˜ì‹ ì í”„ë¡œì„¸ìŠ¤"""
        while True:
            try:
                message = conn.recv()
                print(f"ìˆ˜ì‹  by {name}: {message}")
            except EOFError:
                break
        
        print(f"ìˆ˜ì‹ ì {name} ì™„ë£Œ")
    
    # íŒŒì´í”„ ìƒì„±
    parent_conn, child_conn = multiprocessing.Pipe()
    
    # í”„ë¡œì„¸ìŠ¤ ìƒì„±
    sender = multiprocessing.Process(
        target=sender_process,
        args=(child_conn, "Sender")
    )
    
    receiver = multiprocessing.Process(
        target=receiver_process,
        args=(parent_conn, "Receiver")
    )
    
    # í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    sender.start()
    receiver.start()
    
    # ì™„ë£Œ ëŒ€ê¸°
    sender.join()
    receiver.join()

if __name__ == "__main__":
    queue_communication()
    pipe_communication()
```

### 3. í”„ë¡œì„¸ìŠ¤ í’€

```python
import multiprocessing
import time
import math

def cpu_intensive_function(n):
    """CPU ì§‘ì•½ì  í•¨ìˆ˜"""
    result = 0
    for i in range(n):
        result += math.sqrt(i)
    return result

def process_pool_demo():
    """í”„ë¡œì„¸ìŠ¤ í’€ ë°ëª¨"""
    print("\n=== í”„ë¡œì„¸ìŠ¤ í’€ ë°ëª¨ ===")
    
    # ì‘ì—… ë°ì´í„°
    work_data = [1000000, 1200000, 800000, 1500000, 900000, 1100000]
    
    # 1. ìˆœì°¨ ì²˜ë¦¬
    print("1. ìˆœì°¨ ì²˜ë¦¬:")
    start_time = time.time()
    sequential_results = [cpu_intensive_function(n) for n in work_data]
    sequential_time = time.time() - start_time
    print(f"ìˆœì°¨ ì²˜ë¦¬ ì‹œê°„: {sequential_time:.2f}ì´ˆ")
    
    # 2. í”„ë¡œì„¸ìŠ¤ í’€ ì²˜ë¦¬
    print("\n2. í”„ë¡œì„¸ìŠ¤ í’€ ì²˜ë¦¬:")
    start_time = time.time()
    
    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:
        pool_results = pool.map(cpu_intensive_function, work_data)
    
    pool_time = time.time() - start_time
    print(f"í”„ë¡œì„¸ìŠ¤ í’€ ì²˜ë¦¬ ì‹œê°„: {pool_time:.2f}ì´ˆ")
    print(f"ì„±ëŠ¥ ê°œì„ : {sequential_time / pool_time:.2f}ë°°")
    
    # ê²°ê³¼ ê²€ì¦
    print(f"ê²°ê³¼ ì¼ì¹˜: {sequential_results == pool_results}")
    
    # 3. ë¹„ë™ê¸° ì²˜ë¦¬
    print("\n3. ë¹„ë™ê¸° í”„ë¡œì„¸ìŠ¤ í’€:")
    start_time = time.time()
    
    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:
        # ë¹„ë™ê¸°ë¡œ ì‘ì—… ì œì¶œ
        async_results = [pool.apply_async(cpu_intensive_function, (n,)) for n in work_data]
        
        # ê²°ê³¼ ìˆ˜ì§‘
        async_final_results = [result.get() for result in async_results]
    
    async_time = time.time() - start_time
    print(f"ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œê°„: {async_time:.2f}ì´ˆ")
    print(f"ê²°ê³¼ ì¼ì¹˜: {sequential_results == async_final_results}")

if __name__ == "__main__":
    process_pool_demo()
```

## concurrent.futures ëª¨ë“ˆ

### 1. ThreadPoolExecutorì™€ ProcessPoolExecutor

```python
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import time
import requests

def io_bound_task(url):
    """I/O ì§‘ì•½ì  ì‘ì—… (ì›¹ ìš”ì²­)"""
    try:
        response = requests.get(url, timeout=5)
        return f"{url}: {response.status_code}"
    except Exception as e:
        return f"{url}: Error - {str(e)}"

def cpu_bound_task(n):
    """CPU ì§‘ì•½ì  ì‘ì—…"""
    total = 0
    for i in range(n * 100000):
        total += i * i
    return total

def concurrent_futures_demo():
    """concurrent.futures ë°ëª¨"""
    print("=== concurrent.futures ë°ëª¨ ===")
    
    # í…ŒìŠ¤íŠ¸ URLë“¤
    urls = [
        "https://httpbin.org/delay/1",
        "https://httpbin.org/delay/2",
        "https://httpbin.org/delay/1",
        "https://httpbin.org/status/200",
        "https://httpbin.org/status/404"
    ]
    
    # 1. ThreadPoolExecutor (I/O ì§‘ì•½ì  ì‘ì—…)
    print("\n1. ThreadPoolExecutor (I/O ì‘ì—…):")
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=5) as executor:
        future_to_url = {executor.submit(io_bound_task, url): url for url in urls}
        
        for future in as_completed(future_to_url):
            url = future_to_url[future]
            try:
                result = future.result()
                print(f"ê²°ê³¼: {result}")
            except Exception as exc:
                print(f"{url} ì˜¤ë¥˜: {exc}")
    
    thread_time = time.time() - start_time
    print(f"ThreadPool ì‹¤í–‰ ì‹œê°„: {thread_time:.2f}ì´ˆ")
    
    # 2. ProcessPoolExecutor (CPU ì§‘ì•½ì  ì‘ì—…)
    print("\n2. ProcessPoolExecutor (CPU ì‘ì—…):")
    cpu_tasks = [10, 15, 8, 12, 20]
    
    start_time = time.time()
    
    with ProcessPoolExecutor(max_workers=4) as executor:
        future_to_task = {executor.submit(cpu_bound_task, n): n for n in cpu_tasks}
        
        for future in as_completed(future_to_task):
            task = future_to_task[future]
            try:
                result = future.result()
                print(f"ì‘ì—… {task}: ê²°ê³¼ {result}")
            except Exception as exc:
                print(f"ì‘ì—… {task} ì˜¤ë¥˜: {exc}")
    
    process_time = time.time() - start_time
    print(f"ProcessPool ì‹¤í–‰ ì‹œê°„: {process_time:.2f}ì´ˆ")

if __name__ == "__main__":
    concurrent_futures_demo()
```

## ì‹¤ìŠµ í”„ë¡œì íŠ¸

###ï¸ í”„ë¡œì íŠ¸ 1: ì›¹ í¬ë¡¤ëŸ¬ (ë©€í‹°ìŠ¤ë ˆë”©)

```python
import threading
import requests
import time
from urllib.parse import urljoin, urlparse
import queue
from collections import defaultdict

class WebCrawler:
    """ë©€í‹°ìŠ¤ë ˆë“œ ì›¹ í¬ë¡¤ëŸ¬"""
    
    def __init__(self, max_workers=5, max_pages=50):
        self.max_workers = max_workers
        self.max_pages = max_pages
        self.url_queue = queue.Queue()
        self.visited_urls = set()
        self.results = defaultdict(dict)
        self.lock = threading.Lock()
        self.session = requests.Session()
        
        # User-Agent ì„¤ì •
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    def is_valid_url(self, url):
        """ìœ íš¨í•œ URLì¸ì§€ í™•ì¸"""
        try:
            parsed = urlparse(url)
            return bool(parsed.netloc) and bool(parsed.scheme)
        except:
            return False
    
    def crawl_page(self, url):
        """ë‹¨ì¼ í˜ì´ì§€ í¬ë¡¤ë§"""
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            # ê²°ê³¼ ì €ì¥
            page_info = {
                'status_code': response.status_code,
                'content_length': len(response.content),
                'title': self.extract_title(response.text),
                'links_found': len(self.extract_links(response.text, url))
            }
            
            with self.lock:
                self.results[url] = page_info
            
            # ìƒˆ ë§í¬ë“¤ì„ íì— ì¶”ê°€
            for link in self.extract_links(response.text, url):
                if link not in self.visited_urls and len(self.visited_urls) < self.max_pages:
                    self.url_queue.put(link)
            
            print(f"âœ“ {url} - {page_info['status_code']} ({page_info['content_length']} bytes)")
            
        except Exception as e:
            with self.lock:
                self.results[url] = {'error': str(e)}
            print(f"âœ— {url} - Error: {str(e)}")
    
    def extract_title(self, html):
        """HTMLì—ì„œ ì œëª© ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)"""
        try:
            start = html.find('<title>') + 7
            end = html.find('</title>')
            if start > 6 and end > start:
                return html[start:end].strip()
        except:
            pass
        return "No title"
    
    def extract_links(self, html, base_url):
        """HTMLì—ì„œ ë§í¬ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)"""
        links = []
        try:
            import re
            # href ì†ì„± ì°¾ê¸°
            href_pattern = r'href=["\']([^"\']+)["\']'
            matches = re.findall(href_pattern, html)
            
            for match in matches[:10]:  # ìµœëŒ€ 10ê°œ ë§í¬ë§Œ
                full_url = urljoin(base_url, match)
                if self.is_valid_url(full_url):
                    links.append(full_url)
        except:
            pass
        return links
    
    def worker(self):
        """ì›Œì»¤ ìŠ¤ë ˆë“œ í•¨ìˆ˜"""
        while True:
            try:
                url = self.url_queue.get(timeout=5)
                
                with self.lock:
                    if url in self.visited_urls or len(self.visited_urls) >= self.max_pages:
                        self.url_queue.task_done()
                        continue
                    self.visited_urls.add(url)
                
                self.crawl_page(url)
                self.url_queue.task_done()
                
            except queue.Empty:
                break
    
    def crawl(self, start_urls):
        """í¬ë¡¤ë§ ì‹œì‘"""
        print(f"ì›¹ í¬ë¡¤ëŸ¬ ì‹œì‘ - ì›Œì»¤: {self.max_workers}, ìµœëŒ€ í˜ì´ì§€: {self.max_pages}")
        
        # ì‹œì‘ URLë“¤ì„ íì— ì¶”ê°€
        for url in start_urls:
            self.url_queue.put(url)
        
        # ì›Œì»¤ ìŠ¤ë ˆë“œë“¤ ì‹œì‘
        threads = []
        for i in range(self.max_workers):
            thread = threading.Thread(target=self.worker)
            thread.daemon = True
            threads.append(thread)
            thread.start()
        
        # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
        self.url_queue.join()
        
        return self.results

# í¬ë¡¤ëŸ¬ ì‚¬ìš© ì˜ˆì œ
def crawler_demo():
    crawler = WebCrawler(max_workers=3, max_pages=10)
    
    start_urls = [
        "https://httpbin.org/",
        "https://python.org/"
    ]
    
    start_time = time.time()
    results = crawler.crawl(start_urls)
    end_time = time.time()
    
    print(f"\ní¬ë¡¤ë§ ì™„ë£Œ!")
    print(f"ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    print(f"ì²˜ë¦¬ëœ í˜ì´ì§€: {len(results)}")
    
    # ê²°ê³¼ ìš”ì•½
    success_count = sum(1 for result in results.values() if 'error' not in result)
    error_count = len(results) - success_count
    
    print(f"ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {error_count}")

if __name__ == "__main__":
    crawler_demo()
```

###ï¸ í”„ë¡œì íŠ¸ 2: ì´ë¯¸ì§€ ì²˜ë¦¬ ë„êµ¬ (ë©€í‹°í”„ë¡œì„¸ì‹±)

```python
import multiprocessing
import os
import time
from PIL import Image
import glob

class ImageProcessor:
    """ë©€í‹°í”„ë¡œì„¸ì‹± ì´ë¯¸ì§€ ì²˜ë¦¬ê¸°"""
    
    def __init__(self, num_processes=None):
        self.num_processes = num_processes or multiprocessing.cpu_count()
    
    @staticmethod
    def resize_image(args):
        """ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ í•¨ìˆ˜"""
        input_path, output_path, size = args
        
        try:
            with Image.open(input_path) as img:
                # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ë¦¬ì‚¬ì´ì¦ˆ
                img.thumbnail(size, Image.Resampling.LANCZOS)
                
                # RGBë¡œ ë³€í™˜ (JPEG ì €ì¥ì„ ìœ„í•´)
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                img.save(output_path, 'JPEG', quality=85)
                
            return f"âœ“ {os.path.basename(input_path)} -> {size}"
            
        except Exception as e:
            return f"âœ— {os.path.basename(input_path)}: {str(e)}"
    
    @staticmethod
    def apply_filter(args):
        """ì´ë¯¸ì§€ í•„í„° ì ìš©"""
        input_path, output_path, filter_type = args
        
        try:
            with Image.open(input_path) as img:
                # RGB ë³€í™˜
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # í•„í„° ì ìš©
                if filter_type == 'grayscale':
                    img = img.convert('L').convert('RGB')
                elif filter_type == 'sepia':
                    # ê°„ë‹¨í•œ ì„¸í”¼ì•„ íš¨ê³¼
                    pixels = img.load()
                    for i in range(img.width):
                        for j in range(img.height):
                            r, g, b = pixels[i, j]
                            tr = int(0.393 * r + 0.769 * g + 0.189 * b)
                            tg = int(0.349 * r + 0.686 * g + 0.168 * b)
                            tb = int(0.272 * r + 0.534 * g + 0.131 * b)
                            pixels[i, j] = (min(255, tr), min(255, tg), min(255, tb))
                
                img.save(output_path, 'JPEG', quality=85)
                
            return f"âœ“ {os.path.basename(input_path)} -> {filter_type}"
            
        except Exception as e:
            return f"âœ— {os.path.basename(input_path)}: {str(e)}"
    
    @staticmethod
    def create_thumbnail(args):
        """ì¸ë„¤ì¼ ìƒì„±"""
        input_path, output_path, size = args
        
        try:
            with Image.open(input_path) as img:
                # ì •ì‚¬ê°í˜• ì¸ë„¤ì¼ ìƒì„±
                img = img.convert('RGB')
                
                # ì¤‘ì•™ì—ì„œ ì •ì‚¬ê°í˜•ìœ¼ë¡œ ìë¥´ê¸°
                width, height = img.size
                min_dimension = min(width, height)
                
                left = (width - min_dimension) // 2
                top = (height - min_dimension) // 2
                right = left + min_dimension
                bottom = top + min_dimension
                
                img = img.crop((left, top, right, bottom))
                img = img.resize(size, Image.Resampling.LANCZOS)
                
                img.save(output_path, 'JPEG', quality=85)
                
            return f"âœ“ {os.path.basename(input_path)} -> thumbnail {size}"
            
        except Exception as e:
            return f"âœ— {os.path.basename(input_path)}: {str(e)}"
    
    def batch_process(self, input_dir, output_dir, operation, **kwargs):
        """ë°°ì¹˜ ì´ë¯¸ì§€ ì²˜ë¦¬"""
        # ì…ë ¥ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì°¾ê¸°
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.gif']
        image_files = []
        
        for ext in image_extensions:
            image_files.extend(glob.glob(os.path.join(input_dir, ext)))
            image_files.extend(glob.glob(os.path.join(input_dir, ext.upper())))
        
        if not image_files:
            print(f"âŒ {input_dir}ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        # ì‘ì—… ì¸ìˆ˜ ì¤€ë¹„
        task_args = []
        for input_file in image_files:
            filename = os.path.splitext(os.path.basename(input_file))[0]
            output_file = os.path.join(output_dir, f"{filename}_processed.jpg")
            
            if operation == 'resize':
                size = kwargs.get('size', (800, 600))
                task_args.append((input_file, output_file, size))
            elif operation == 'filter':
                filter_type = kwargs.get('filter_type', 'grayscale')
                task_args.append((input_file, output_file, filter_type))
            elif operation == 'thumbnail':
                size = kwargs.get('size', (150, 150))
                task_args.append((input_file, output_file, size))
        
        # ì‘ì—… í•¨ìˆ˜ ì„ íƒ
        work_function = {
            'resize': self.resize_image,
            'filter': self.apply_filter,
            'thumbnail': self.create_thumbnail
        }.get(operation)
        
        if not work_function:
            print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—…: {operation}")
            return
        
        print(f"ğŸš€ {len(task_args)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘ ({operation})")
        print(f"í”„ë¡œì„¸ìŠ¤ ìˆ˜: {self.num_processes}")
        
        # ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ ì²˜ë¦¬
        start_time = time.time()
        
        with multiprocessing.Pool(processes=self.num_processes) as pool:
            results = pool.map(work_function, task_args)
        
        end_time = time.time()
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nì²˜ë¦¬ ê²°ê³¼:")
        for result in results:
            print(result)
        
        success_count = sum(1 for r in results if r.startswith('âœ“'))
        error_count = len(results) - success_count
        
        print(f"\nğŸ“Š ìš”ì•½:")
        print(f"ì²˜ë¦¬ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
        print(f"ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {error_count}")
        print(f"ì´ˆë‹¹ ì²˜ë¦¬: {len(results)/(end_time - start_time):.2f} ì´ë¯¸ì§€/ì´ˆ")

# ì‚¬ìš© ì˜ˆì œ
def image_processing_demo():
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ë°ëª¨"""
    # ë°ëª¨ìš© ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±
    def create_sample_images():
        sample_dir = "sample_images"
        os.makedirs(sample_dir, exist_ok=True)
        
        # PILë¡œ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        colors = ['red', 'green', 'blue', 'yellow', 'purple']
        for i, color in enumerate(colors):
            img = Image.new('RGB', (400, 300), color)
            img.save(os.path.join(sample_dir, f"sample_{i+1}.jpg"))
        
        return sample_dir
    
    # ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±
    input_dir = create_sample_images()
    
    # ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ ìƒì„±
    processor = ImageProcessor(num_processes=2)
    
    # 1. ë¦¬ì‚¬ì´ì¦ˆ ì‘ì—…
    print("=== ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ===")
    processor.batch_process(
        input_dir, 
        "resized_images", 
        "resize", 
        size=(200, 150)
    )
    
    # 2. í•„í„° ì ìš©
    print("\n=== ê·¸ë ˆì´ìŠ¤ì¼€ì¼ í•„í„° ===")
    processor.batch_process(
        input_dir, 
        "filtered_images", 
        "filter", 
        filter_type="grayscale"
    )
    
    # 3. ì¸ë„¤ì¼ ìƒì„±
    print("\n=== ì¸ë„¤ì¼ ìƒì„± ===")
    processor.batch_process(
        input_dir, 
        "thumbnails", 
        "thumbnail", 
        size=(100, 100)
    )

if __name__ == "__main__":
    image_processing_demo()
```

## ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë™ì‹œì„± ê¸°ë³¸ ê°œë…
- [ ] ë™ì‹œì„±ê³¼ ë³‘ë ¬ì„±ì˜ ì°¨ì´ì  ì´í•´
- [ ] GILì˜ ì˜í–¥ê³¼ ì œì•½ì‚¬í•­ íŒŒì•…
- [ ] I/O ë°”ìš´ë“œ vs CPU ë°”ìš´ë“œ ì‘ì—… êµ¬ë¶„
- [ ] ì ì ˆí•œ ë™ì‹œì„± ëª¨ë¸ ì„ íƒ ëŠ¥ë ¥

### ë©€í‹°ìŠ¤ë ˆë”©
- [ ] Thread í´ë˜ìŠ¤ë¡œ ìŠ¤ë ˆë“œ ìƒì„±
- [ ] Lockì„ ì‚¬ìš©í•œ ë™ê¸°í™”
- [ ] ìƒì‚°ì-ì†Œë¹„ì íŒ¨í„´ êµ¬í˜„
- [ ] ìŠ¤ë ˆë“œ ì•ˆì „ì„± ê³ ë ¤

### ë©€í‹°í”„ë¡œì„¸ì‹±
- [ ] Process í´ë˜ìŠ¤ë¡œ í”„ë¡œì„¸ìŠ¤ ìƒì„±
- [ ] Queue, Pipeë¡œ í”„ë¡œì„¸ìŠ¤ ê°„ í†µì‹ 
- [ ] ProcessPoolì„ í™œìš©í•œ ë³‘ë ¬ì²˜ë¦¬
- [ ] ê³µìœ  ë©”ëª¨ë¦¬ ì‚¬ìš©

### concurrent.futures
- [ ] ThreadPoolExecutor í™œìš©
- [ ] ProcessPoolExecutor í™œìš©
- [ ] Future ê°ì²´ ì´í•´
- [ ] as_completed() íŒ¨í„´ í™œìš©

### ë™ì‹œì„± ë¬¸ì œ í•´ê²°
- [ ] Race Condition ë°©ì§€
- [ ] ë°ë“œë½ íšŒí”¼
- [ ] ì„±ëŠ¥ ìµœì í™” ê³ ë ¤
- [ ] ì ì ˆí•œ ì›Œì»¤ ìˆ˜ ì„¤ì •

## ë‹¤ìŒ ë‹¨ê³„

ğŸ‰ **ì¶•í•˜í•©ë‹ˆë‹¤!** ë™ì‹œì„± í”„ë¡œê·¸ë˜ë°ì„ ë§ˆìŠ¤í„°í–ˆìŠµë‹ˆë‹¤.

ë™ì‹œì„± ì²˜ë¦¬ëŠ” í˜„ëŒ€ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤. ì´ì œ [18. ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°](../18_async_programming/)ìœ¼ë¡œ ë„˜ì–´ê°€ì„œ ë”ìš± íš¨ìœ¨ì ì¸ ë¹„ë™ê¸° ì²˜ë¦¬ íŒ¨ëŸ¬ë‹¤ì„ì„ í•™ìŠµí•´ë´…ì‹œë‹¤.

---

ğŸ’¡ **ë™ì‹œì„± í”„ë¡œê·¸ë˜ë° ê°€ì´ë“œ:**
- **I/O ì‘ì—…ì´ ë§ë‹¤ë©´** â†’ ë©€í‹°ìŠ¤ë ˆë”© ë˜ëŠ” ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°
- **CPU ì‘ì—…ì´ ë§ë‹¤ë©´** â†’ ë©€í‹°í”„ë¡œì„¸ì‹±
- **ê°„ë‹¨í•œ ë³‘ë ¬ì²˜ë¦¬** â†’ concurrent.futures ì‚¬ìš©
- **ë³µì¡í•œ ë™ì‹œì„±** â†’ threading/multiprocessing ì§ì ‘ ì‚¬ìš©
- **ì„±ëŠ¥ ì¸¡ì • í•„ìˆ˜** â†’ ì‹¤ì œ ì›Œí¬ë¡œë“œë¡œ ë²¤ì¹˜ë§ˆí‚¹ 