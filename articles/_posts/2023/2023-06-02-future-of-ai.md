---
title: "[AI] AI의 미래 - 기회, 위험, 오픈 소스 연구의 필요성"
categories: AI
tags:
- Artificial Intelligence
- AI Research
- Open Source
- AI Ethics
- AI Safety
- AI Development
- AI Risks
- AI Policy
- AI Transparency
- AI Accountability
- Future of AI
- Society
- Economy
- Innovation
- Corporations
- Small Businesses
- Education
- Government
- Human Impact
- Global Cooperation
header:
  teaser: /assets/images/2023/GettyImages-676338286-1-scaled.jpg
---

인공지능(AI)은 현대 기술의 초석이 되어 의료에서 금융, 교육에서 엔터테인먼트에 이르기까지 무수히 많은 분야에 영향을 미치고 있습니다. 공상 과학 소설의 소재였던 혁신과 효율성의 기회를 제공하면서 세상을 혁신할 수 있는 잠재력은 엄청납니다. 그러나 다른 강력한 도구와 마찬가지로 AI의 부상에는 신중하게 관리해야 하는 여러 가지 과제와 위험도 수반됩니다.

이 블로그 게시물에서는 AI의 다각적인 측면을 살펴보고 AI의 유망한 잠재력과 제기되는 우려를 모두 살펴볼 것입니다. AI의 잠재적 해악에 대한 AI 선구자 제프리 힌튼의 경고에 대해 논의하고, AI 개발의 인적 비용을 강조하는 사례 연구를 공유합니다. 또한 오픈소스 AI 연구에 대한 요구가 커지고 있는 상황과 AI 개발에서 대기업의 역할에 대해서도 살펴볼 것입니다. 마지막으로, AI 연구를 위한 CERN과 유사한 시설에 대한 제안과 사회에 대한 잠재적 이점을 살펴봅니다.

![](/assets/images/2023/GettyImages-676338286-1-scaled.jpg)

# 인공지능의 위험성

인공지능은 유망한 기술이지만 위험이 없는 것은 아닙니다. 이러한 위험은 윤리적인 것부터 심리적인 것까지 다양하며, AI가 계속 진화하고 우리 삶에 스며들면서 점점 더 분명해지고 있습니다.

AI의 잠재적 해악에 대해 우려를 표명하는 대표적인 인물 중 한 명은 딥러닝 분야의 선구자인 제프리 힌튼입니다. 힌튼은 최근 MIT 테크놀로지 리뷰와의 인터뷰에서 AI의 잠재적 위험성에 대한 우려가 커지면서 구글 AI 연구원직에서 물러나기로 결정했다고 밝혔습니다. 힌튼은 인류가 지능의 진화 과정에서 지나가는 단계에 불과할 수 있다는 냉정한 견해를 밝혔습니다. 그의 우려는 AI 기술의 개발과 배포에 있어 신중한 고려와 규제가 필요하다는 점을 강조합니다.

하지만 AI의 위험은 단순히 이론적이거나 미래 지향적인 것이 아닙니다. AI 개발의 최전선에서 일하는 사람들의 경험에서 알 수 있듯이 이러한 위험은 현재에도 현실적으로 존재합니다. 케냐 나이로비의 리처드 마테엔게와 그의 팀이 OpenAI의 GPT 모델을 훈련하는 임무를 맡았던 이야기가 대표적인 사례입니다.

일주일에 5일, 하루 9시간씩 마테엔게와 그의 팀은 노골적이고 불온한 콘텐츠에 노출되어 AI 모델에 라벨을 지정해야 했습니다. 이들이 접한 콘텐츠는 아동 학대 및 기타 형태의 성폭력에 대한 묘사와 함께 심각한 트라우마를 유발하는 경우가 많았습니다. 이 작업으로 인한 심리적 피해는 엄청났고, 불면증, 불안, 우울증, 심지어 인간관계의 붕괴로까지 이어졌습니다.

이 사례 연구는 AI 개발로 인한 인적 비용을 극명하게 보여줍니다. 이 사례 연구는 AI 모델 학습에 참여하는 사람들을 위한 더 나은 지원과 보호의 필요성과 이러한 기술의 개발 및 배포 시 고려해야 할 윤리적 고려 사항을 강조합니다.

# 오픈 소스 AI 연구의 필요성

AI의 힘과 영향력이 계속 커짐에 따라 AI 연구에 대한 민주화된 접근의 필요성도 커지고 있습니다. 최근 한 청원에서는 오픈 소스 AI 연구 전용의 국제적인 공적 자금 지원 슈퍼컴퓨팅 시설의 설립을 촉구하고 있습니다. 일종의 AI용 CERN으로 구상되는 이 시설에는 오픈 소스 기반 모델을 훈련할 수 있는 최첨단 AI 가속기가 설치될 것입니다.

이러한 이니셔티브의 잠재적 이점은 다양합니다. 첫째, 기술 독립성을 촉진하여 현재 AI 환경을 지배하고 있는 일부 대기업에 대한 의존도를 줄일 수 있습니다. 이는 교육 기관, 정부 기관 및 국가 전체가 투명성이나 공적 책임이 거의 없이 운영되는 이러한 기업에 종속되지 않도록 하는 데 도움이 될 것입니다.

둘째, 이 이니셔티브는 글로벌 혁신을 촉진할 것입니다. 전 세계의 연구자와 기관에 고급 AI 모델에 대한 액세스를 제공함으로써 이러한 기술의 잠재력을 최대한 활용하여 사회를 개선할 수 있게 될 것입니다. 이는 학술 연구를 크게 풍부하게 하고, 투명성을 높이며, 데이터 보안을 보장할 수 있습니다.

셋째, 이 프로젝트의 오픈소스 특성은 안전 및 보안 연구를 촉진할 것입니다. 이를 통해 잠재적인 위험을 보다 신속하고 투명하게 식별하고 해결할 수 있으며, 이는 AI 기술이 우리 삶에 점점 더 통합되는 상황에서 안전과 신뢰성을 보장하는 데 필수적인 단계입니다.

그러나 AI 연구와 접근이 민주화되지 않으면 우리 공동의 미래에 심각한 영향을 미칠 수 있습니다. AI 전문 지식과 자원이 대기업에 집중되면 투명성이 부족해지고 혁신이 억제되며 AI 기술이 오용될 가능성이 있습니다. 따라서 우리는 AI 연구를 민주화하고 모든 사람이 그 혜택을 누리고 접근할 수 있도록 조치를 취해야 합니다.

# AI 개발에서 대기업의 역할

현재 AI 개발 환경에서는 Google, Microsoft, OpenAI와 같은 몇몇 대기업이 상당한 영향력을 행사하고 있습니다. 이러한 대기업은 데이터, 연산 능력, 인적 전문성 등 방대한 리소스에 접근할 수 있어 AI 기술을 발전시키는 데 상당한 이점을 가지고 있습니다.

그러나 이러한 우위는 몇 가지 우려를 불러일으킵니다. 가장 중요한 것 중 하나는 투명성이 부족하다는 점입니다. 이러한 기업들은 종종 블랙박스처럼 운영되며, 대중은 내부 운영이나 의사 결정 과정에 대한 통찰력을 거의 갖지 못합니다. 이러한 투명성 부족은 데이터 사용에 대한 윤리적 문제부터 AI 알고리즘의 공정성 및 편향성에 대한 의문까지 다양한 문제를 야기할 수 있습니다.

또 다른 우려는 공적 책임의 부재입니다. 민간 기업으로서 이러한 기업은 주로 주주에 대한 책임이 있으며, 이는 때때로 더 광범위한 공익과 상충될 수 있습니다. 예를 들어, 윤리적 고려나 사회적 영향보다 이윤을 우선시하여 사회에 부정적인 결과를 초래할 수 있는 결정을 내릴 수 있습니다.

이러한 우려를 고려할 때 소규모 기업, 학술 기관, 국가가 AI 개발에서 자율성을 주장하는 것이 중요합니다. 이러한 주체들은 AI 연구와 개발에 적극적으로 참여함으로써 보다 다양하고 균형 잡힌 AI 환경을 조성하는 데 기여할 수 있습니다. 이들은 대안적인 관점을 제시하고, 윤리적 관행을 장려하며, AI의 혜택이 보다 공평하게 분배되도록 할 수 있습니다.

대기업이 AI 개발에서 중요한 역할을 하는 것은 의심할 여지가 없지만, 대기업이 이 분야를 독점하지 않도록 하는 것이 중요합니다. 보다 다양하고 포용적인 AI 생태계는 더욱 강력하고 윤리적이며 유익한 AI 기술로 이어질 것입니다.

# AI 연구를 위한 CERN과 같은 시설에 대한 제안

공개적으로 자금을 지원하는 국제적인 오픈 소스 슈퍼컴퓨팅 연구 시설에 대한 제안은 AI 연구의 민주화를 목표로 하는 대담하고 야심찬 이니셔티브입니다. 유럽입자물리연구소(CERN)에서 영감을 얻은 이 시설은 AI 연구 및 개발을 위한 글로벌 허브가 될 것입니다.

이 시설에는 최소 10만 대 이상의 GPU 또는 ASIC과 같은 고성능 최첨단 가속기가 장착된 다양한 기계가 들어설 것입니다. 이러한 기계는 머신러닝 및 슈퍼컴퓨팅 연구 커뮤니티의 전문가들이 운영하며, 민주적으로 선출된 참여국의 기관이 감독하게 됩니다.

이 시설은 전 세계 연구자와 기관에 고급 AI 모델에 대한 액세스를 제공함으로써 AI 연구를 민주화할 것입니다. 이러한 모델을 오픈 소스로 공개하고 멀티모달 데이터(오디오, 비디오, 텍스트, 프로그램 코드)를 통합함으로써 이 시설은 학술 연구를 크게 풍부하게 하고, 투명성을 높이며, 데이터 보안을 보장할 수 있습니다.

또한, 이 프로젝트의 오픈 소스 특성은 안전 및 보안 연구를 촉진할 것입니다. 잠재적 위험을 보다 신속하고 투명하게 식별하고 해결할 수 있게 함으로써 이 시설은 AI 기술의 안전성과 신뢰성을 보장하는 데 중요한 역할을 할 수 있습니다.

이러한 이점 외에도 제안된 시설은 전 세계 중소기업에 상당한 경제적 이익을 가져다 줄 수 있습니다. 대규모 기초 모델에 대한 액세스를 제공함으로써 기업은 가중치와 데이터에 대한 완전한 통제권을 유지하면서 특정 사용 사례에 맞게 모델을 미세 조정할 수 있습니다. 이러한 접근 방식은 운영에서 AI 애플리케이션에 대한 투명성과 통제권을 원하는 정부 기관에도 어필할 수 있습니다.

결론적으로, 제안된 국제적인 공공 자금 지원 오픈소스 슈퍼컴퓨팅 연구 시설은 보다 공평하고 포용적인 AI 환경을 향한 중요한 발걸음을 내딛는 것입니다. 이 시설은 AI 연구를 민주화하고, 안전과 보안을 증진하며, 혁신을 촉진함으로써 AI의 미래를 형성하는 데 중요한 역할을 할 수 있습니다.

# 결론

이번 블로그 게시물에서는 AI의 잠재적 혜택과 잠재적 위험, 그리고 민주화된 오픈소스 AI 연구의 시급한 필요성에 대해 살펴보며 다각도로 AI의 세계를 살펴봤습니다. AI의 선구자 제프리 힌튼이 제기한 우려에 대해 논의하고, 리처드 마테엔지와 그의 팀이 AI 개발의 인적 비용을 강조하며 겪은 냉정한 경험을 공유했습니다.

또한 AI 연구를 위해 CERN과 같은 국제적인 공공 자금 지원 오픈 소스 슈퍼컴퓨팅 연구 시설에 대한 제안을 검토했습니다. 이 시설은 AI 연구를 민주화하고, 안전과 보안을 증진하며, 글로벌 혁신을 촉진하고, 전 세계 중소기업에 상당한 경제적 이익을 가져다줄 수 있습니다.

하지만 AI의 미래는 이미 정해진 결론이 아닙니다. 우리 사회가 아직 개척해 나가고 있는 길입니다. 따라서 독자 여러분께서도 오픈소스 AI 연구 시설에 대한 청원을 지지해 주시기 바랍니다. 그렇게 함으로써 누구나 AI 기술에 접근할 수 있고, 혁신과 발전이 소수의 강력한 기업에 의해 제한되지 않으며, 모든 인류가 AI의 혜택을 누릴 수 있는 미래를 만드는 데 도움을 줄 수 있습니다.

복잡한 AI 환경을 계속 탐색해 나가면서 투명성, 책임성, 포용성의 원칙에 따라 개발이 이루어질 수 있도록 노력합시다. AI의 미래는 엄청난 잠재력을 가지고 있지만, 이러한 잠재력이 모두를 위해 활용될 수 있도록 하는 것은 우리의 몫입니다.

# 참고

* https://news.ycombinator.com/item?id=36134249
* https://www.technologyreview.com/2023/05/03/1072589/video-geoffrey-hinton-google-ai-risk-ethics/
* https://www.openpetition.eu/petition/online/securing-our-digital-future-a-cern-for-open-source-large-scale-ai-research-and-its-safety
* https://www.bigtechnology.com/p/he-helped-train-chatgpt-it-traumatized